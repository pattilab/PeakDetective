{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deimos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import random as rd\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "import sys\n",
    "import PeakDetective\n",
    "import PeakDetective.detection_helper as detection_helper\n",
    "import scipy.stats as stats\n",
    "import seaborn as sb\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as met\n",
    "import random as rd\n",
    "import importlib\n",
    "import pickle as pkl\n",
    "import NeatMS as ntms\n",
    "\n",
    "def makePRCPlot(pred,true,noSkill=True,label=\"\"):\n",
    "\n",
    "    prec, recall, threshs = met.precision_recall_curve(true, pred)\n",
    "\n",
    "    auc = np.round(met.auc(recall, prec), 4)\n",
    "\n",
    "    plt.plot(recall, prec, label=label + \" prAUC=\" + str(auc))\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    if noSkill:\n",
    "        numPositive = len([x for x in true if x > 0.5])\n",
    "        numNegative = len(true) - numPositive\n",
    "        plt.plot([0, 1.0],\n",
    "                 [numPositive / float(numPositive + numNegative), numPositive / float(numPositive + numNegative)],\n",
    "                 label=\"NSL prAUC=\" + str(\n",
    "                     np.round(numPositive / float(numPositive + numNegative), 4)))\n",
    "    plt.legend()\n",
    "    return auc\n",
    "\n",
    "def makeViolinPlot(pred,true):\n",
    "    \n",
    "    plt_dict = {}\n",
    "    \n",
    "    for p,t in zip(pred,true):\n",
    "        if t > 0.5:\n",
    "            group = \"true peak\"\n",
    "        else:\n",
    "            group = \"artifact\"\n",
    "        plt_dict[len(plt_dict)] = {\"group\":group,\"prediction\":p}\n",
    "        \n",
    "    plt_dict = pd.DataFrame.from_dict(plt_dict,orient=\"index\")\n",
    "    \n",
    "    sb.violinplot(data=plt_dict,x=\"group\",y=\"prediction\",cut=0)\n",
    "\n",
    "def makeROCPlot(pred,true,label=\"\",noSkill=True):\n",
    "\n",
    "    fpr, tpr, threshs = met.roc_curve(true, pred)\n",
    "\n",
    "    auc = np.round(met.auc(fpr, tpr), 4)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=label + \": AUROC=\" + str(auc))\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    if noSkill:\n",
    "        plt.plot([0, 1.0],[0,1.0],label=\"NSL\")\n",
    "    plt.legend()\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"D:/PeakDetective/data/covid_plasma/\"\n",
    "resolution = 60\n",
    "window = 1.0\n",
    "rawDataDir = datadir + \"tmp/\"\n",
    "ms1ppm = 25.5\n",
    "cutoff=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mz</th>\n",
       "      <th>rt</th>\n",
       "      <th>rt_start</th>\n",
       "      <th>rt_end</th>\n",
       "      <th>B1_NIST1950_1_6540.mzML</th>\n",
       "      <th>B1_NIST1950_2_6540.mzML</th>\n",
       "      <th>B1_NIST1950_3_6540.mzML</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FT0001</th>\n",
       "      <td>52.995274</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>5.057352</td>\n",
       "      <td>5.090650</td>\n",
       "      <td>7.850117e+03</td>\n",
       "      <td>6.526800e+03</td>\n",
       "      <td>2.891458e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT0002</th>\n",
       "      <td>54.977012</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>5.073996</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>1.532210e+05</td>\n",
       "      <td>1.210493e+05</td>\n",
       "      <td>1.215186e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT0003</th>\n",
       "      <td>55.018832</td>\n",
       "      <td>6.038233</td>\n",
       "      <td>6.038233</td>\n",
       "      <td>6.038233</td>\n",
       "      <td>6.447720e+03</td>\n",
       "      <td>9.208602e+03</td>\n",
       "      <td>7.405622e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT0004</th>\n",
       "      <td>56.995900</td>\n",
       "      <td>13.086900</td>\n",
       "      <td>13.070283</td>\n",
       "      <td>13.103534</td>\n",
       "      <td>6.127502e+06</td>\n",
       "      <td>5.300639e+06</td>\n",
       "      <td>5.151324e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT0005</th>\n",
       "      <td>57.034581</td>\n",
       "      <td>1.590991</td>\n",
       "      <td>1.566317</td>\n",
       "      <td>1.615666</td>\n",
       "      <td>3.627522e+04</td>\n",
       "      <td>2.545522e+04</td>\n",
       "      <td>3.088248e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT4184</th>\n",
       "      <td>1612.974722</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>1.910637e+04</td>\n",
       "      <td>1.483741e+05</td>\n",
       "      <td>1.705465e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT4185</th>\n",
       "      <td>1612.976154</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>1.358256e+04</td>\n",
       "      <td>1.228282e+04</td>\n",
       "      <td>1.231674e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT4186</th>\n",
       "      <td>1613.978101</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>3.174946e+03</td>\n",
       "      <td>5.177959e+04</td>\n",
       "      <td>2.920245e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT4187</th>\n",
       "      <td>1613.977307</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>2.855932e+04</td>\n",
       "      <td>4.999942e+04</td>\n",
       "      <td>2.388595e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT4188</th>\n",
       "      <td>1613.978958</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>1.325275e+04</td>\n",
       "      <td>1.525656e+04</td>\n",
       "      <td>2.264250e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4188 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mz         rt   rt_start     rt_end  B1_NIST1950_1_6540.mzML  \\\n",
       "FT0001    52.995274   5.074017   5.057352   5.090650             7.850117e+03   \n",
       "FT0002    54.977012   5.074017   5.073996   5.074017             1.532210e+05   \n",
       "FT0003    55.018832   6.038233   6.038233   6.038233             6.447720e+03   \n",
       "FT0004    56.995900  13.086900  13.070283  13.103534             6.127502e+06   \n",
       "FT0005    57.034581   1.590991   1.566317   1.615666             3.627522e+04   \n",
       "...             ...        ...        ...        ...                      ...   \n",
       "FT4184  1612.974722   2.214650   2.214650   2.214650             1.910637e+04   \n",
       "FT4185  1612.976154  14.982067  14.982067  14.982067             1.358256e+04   \n",
       "FT4186  1613.978101   2.214650   2.214650   2.214650             3.174946e+03   \n",
       "FT4187  1613.977307  14.982067  14.982067  14.982067             2.855932e+04   \n",
       "FT4188  1613.978958  12.721182  12.721182  12.721182             1.325275e+04   \n",
       "\n",
       "        B1_NIST1950_2_6540.mzML  B1_NIST1950_3_6540.mzML  \n",
       "FT0001             6.526800e+03             2.891458e+05  \n",
       "FT0002             1.210493e+05             1.215186e+05  \n",
       "FT0003             9.208602e+03             7.405622e+03  \n",
       "FT0004             5.300639e+06             5.151324e+06  \n",
       "FT0005             2.545522e+04             3.088248e+04  \n",
       "...                         ...                      ...  \n",
       "FT4184             1.483741e+05             1.705465e+04  \n",
       "FT4185             1.228282e+04             1.231674e+04  \n",
       "FT4186             5.177959e+04             2.920245e+03  \n",
       "FT4187             4.999942e+04             2.388595e+04  \n",
       "FT4188             1.525656e+04             2.264250e+04  \n",
       "\n",
       "[4188 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det = detection_helper.PeakList()\n",
    "det.readXCMSPeakList(datadir+\"xcms_peak_list.csv\")\n",
    "peakList = pd.DataFrame(det.peakList)\n",
    "peakList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B1_NIST1950_1_6540.mzML', 'B1_NIST1950_2_6540.mzML', 'B1_NIST1950_3_6540.mzML']\n"
     ]
    }
   ],
   "source": [
    "files = [x for x in os.listdir(datadir) if \".mzML\" in x]\n",
    "print(files)\n",
    "raw_data = []\n",
    "for file in files:\n",
    "    temp = PeakDetective.rawData()\n",
    "    temp.readRawDataFile(datadir + file,ms1ppm)\n",
    "    raw_data.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "integ = PeakDetective.PeakDetective(numCores = 15,resolution=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakList_labeled = pd.read_csv(datadir + files[0].replace(\".mzML\",\"_classified_peaks.csv\"),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mz</th>\n",
       "      <th>rt</th>\n",
       "      <th>rtmin</th>\n",
       "      <th>rtmax</th>\n",
       "      <th>feature_id</th>\n",
       "      <th>sample</th>\n",
       "      <th>into</th>\n",
       "      <th>mzmin</th>\n",
       "      <th>mzmax</th>\n",
       "      <th>intb</th>\n",
       "      <th>maxo</th>\n",
       "      <th>sn</th>\n",
       "      <th>sample_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.995274</td>\n",
       "      <td>304.441000</td>\n",
       "      <td>291.441101</td>\n",
       "      <td>303.441101</td>\n",
       "      <td>FT0001</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "      <td>7.850117e+03</td>\n",
       "      <td>52.993922</td>\n",
       "      <td>52.996625</td>\n",
       "      <td>7.850117e+03</td>\n",
       "      <td>7.850117e+03</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.977012</td>\n",
       "      <td>304.441000</td>\n",
       "      <td>292.439758</td>\n",
       "      <td>304.439758</td>\n",
       "      <td>FT0002</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "      <td>1.532210e+05</td>\n",
       "      <td>54.975611</td>\n",
       "      <td>54.978414</td>\n",
       "      <td>1.532210e+05</td>\n",
       "      <td>1.532210e+05</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.018832</td>\n",
       "      <td>362.294000</td>\n",
       "      <td>350.294000</td>\n",
       "      <td>362.294000</td>\n",
       "      <td>FT0003</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "      <td>6.447720e+03</td>\n",
       "      <td>55.017429</td>\n",
       "      <td>55.020235</td>\n",
       "      <td>6.447720e+03</td>\n",
       "      <td>6.447720e+03</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.995900</td>\n",
       "      <td>785.214000</td>\n",
       "      <td>772.216980</td>\n",
       "      <td>784.216980</td>\n",
       "      <td>FT0004</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "      <td>6.127502e+06</td>\n",
       "      <td>56.994447</td>\n",
       "      <td>56.997353</td>\n",
       "      <td>6.127502e+06</td>\n",
       "      <td>6.127502e+06</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.034581</td>\n",
       "      <td>95.459482</td>\n",
       "      <td>81.979000</td>\n",
       "      <td>93.979000</td>\n",
       "      <td>FT0005</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "      <td>3.627522e+04</td>\n",
       "      <td>57.033127</td>\n",
       "      <td>57.036036</td>\n",
       "      <td>3.627522e+04</td>\n",
       "      <td>3.627522e+04</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_1_6540.mzML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12559</th>\n",
       "      <td>1612.974722</td>\n",
       "      <td>132.879000</td>\n",
       "      <td>120.879000</td>\n",
       "      <td>132.879000</td>\n",
       "      <td>FT4184</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "      <td>1.705465e+04</td>\n",
       "      <td>1612.933591</td>\n",
       "      <td>1613.015853</td>\n",
       "      <td>1.705465e+04</td>\n",
       "      <td>1.705465e+04</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12560</th>\n",
       "      <td>1612.976154</td>\n",
       "      <td>898.924000</td>\n",
       "      <td>886.924000</td>\n",
       "      <td>898.924000</td>\n",
       "      <td>FT4185</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "      <td>1.231674e+04</td>\n",
       "      <td>1612.935023</td>\n",
       "      <td>1613.017285</td>\n",
       "      <td>1.231674e+04</td>\n",
       "      <td>1.231674e+04</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12561</th>\n",
       "      <td>1613.978101</td>\n",
       "      <td>132.879000</td>\n",
       "      <td>120.879000</td>\n",
       "      <td>132.879000</td>\n",
       "      <td>FT4186</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "      <td>2.920245e+03</td>\n",
       "      <td>1613.936944</td>\n",
       "      <td>1614.019257</td>\n",
       "      <td>2.920245e+03</td>\n",
       "      <td>2.920245e+03</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12562</th>\n",
       "      <td>1613.977307</td>\n",
       "      <td>898.924000</td>\n",
       "      <td>886.924000</td>\n",
       "      <td>898.924000</td>\n",
       "      <td>FT4187</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "      <td>2.388595e+04</td>\n",
       "      <td>1613.936151</td>\n",
       "      <td>1614.018464</td>\n",
       "      <td>2.388595e+04</td>\n",
       "      <td>2.388595e+04</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12563</th>\n",
       "      <td>1613.978958</td>\n",
       "      <td>763.270935</td>\n",
       "      <td>751.270935</td>\n",
       "      <td>763.270935</td>\n",
       "      <td>FT4188</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "      <td>2.264250e+04</td>\n",
       "      <td>1613.937802</td>\n",
       "      <td>1614.020115</td>\n",
       "      <td>2.264250e+04</td>\n",
       "      <td>2.264250e+04</td>\n",
       "      <td>10</td>\n",
       "      <td>B1_NIST1950_3_6540.mzML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12564 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                mz          rt       rtmin       rtmax feature_id  \\\n",
       "0        52.995274  304.441000  291.441101  303.441101     FT0001   \n",
       "1        54.977012  304.441000  292.439758  304.439758     FT0002   \n",
       "2        55.018832  362.294000  350.294000  362.294000     FT0003   \n",
       "3        56.995900  785.214000  772.216980  784.216980     FT0004   \n",
       "4        57.034581   95.459482   81.979000   93.979000     FT0005   \n",
       "...            ...         ...         ...         ...        ...   \n",
       "12559  1612.974722  132.879000  120.879000  132.879000     FT4184   \n",
       "12560  1612.976154  898.924000  886.924000  898.924000     FT4185   \n",
       "12561  1613.978101  132.879000  120.879000  132.879000     FT4186   \n",
       "12562  1613.977307  898.924000  886.924000  898.924000     FT4187   \n",
       "12563  1613.978958  763.270935  751.270935  763.270935     FT4188   \n",
       "\n",
       "                        sample          into        mzmin        mzmax  \\\n",
       "0      B1_NIST1950_1_6540.mzML  7.850117e+03    52.993922    52.996625   \n",
       "1      B1_NIST1950_1_6540.mzML  1.532210e+05    54.975611    54.978414   \n",
       "2      B1_NIST1950_1_6540.mzML  6.447720e+03    55.017429    55.020235   \n",
       "3      B1_NIST1950_1_6540.mzML  6.127502e+06    56.994447    56.997353   \n",
       "4      B1_NIST1950_1_6540.mzML  3.627522e+04    57.033127    57.036036   \n",
       "...                        ...           ...          ...          ...   \n",
       "12559  B1_NIST1950_3_6540.mzML  1.705465e+04  1612.933591  1613.015853   \n",
       "12560  B1_NIST1950_3_6540.mzML  1.231674e+04  1612.935023  1613.017285   \n",
       "12561  B1_NIST1950_3_6540.mzML  2.920245e+03  1613.936944  1614.019257   \n",
       "12562  B1_NIST1950_3_6540.mzML  2.388595e+04  1613.936151  1614.018464   \n",
       "12563  B1_NIST1950_3_6540.mzML  2.264250e+04  1613.937802  1614.020115   \n",
       "\n",
       "               intb          maxo  sn              sample_name  \n",
       "0      7.850117e+03  7.850117e+03  10  B1_NIST1950_1_6540.mzML  \n",
       "1      1.532210e+05  1.532210e+05  10  B1_NIST1950_1_6540.mzML  \n",
       "2      6.447720e+03  6.447720e+03  10  B1_NIST1950_1_6540.mzML  \n",
       "3      6.127502e+06  6.127502e+06  10  B1_NIST1950_1_6540.mzML  \n",
       "4      3.627522e+04  3.627522e+04  10  B1_NIST1950_1_6540.mzML  \n",
       "...             ...           ...  ..                      ...  \n",
       "12559  1.705465e+04  1.705465e+04  10  B1_NIST1950_3_6540.mzML  \n",
       "12560  1.231674e+04  1.231674e+04  10  B1_NIST1950_3_6540.mzML  \n",
       "12561  2.920245e+03  2.920245e+03  10  B1_NIST1950_3_6540.mzML  \n",
       "12562  2.388595e+04  2.388595e+04  10  B1_NIST1950_3_6540.mzML  \n",
       "12563  2.264250e+04  2.264250e+04  10  B1_NIST1950_3_6540.mzML  \n",
       "\n",
       "[12564 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neatMSPeakList = pd.read_csv(datadir + \"xcms_peak_list.csv\",sep=\"\\t\",index_col=0)\n",
    "neatMSPeakList[\"feature_id\"] = neatMSPeakList.index.values\n",
    "neatMSPeakList[\"feature_id2\"] = neatMSPeakList.index.values\n",
    "neatMSPeakList = neatMSPeakList.melt(id_vars = [\"mzmed\",\"rtmed\",\"rtmin\",\"rtmax\",\"feature_id\"],\n",
    "                    value_vars = [x for x in neatMSPeakList.columns.values if \".mzML\" in x],\n",
    "                   var_name=\"sample\", value_name=\"into\")\n",
    "neatMSPeakList[\"mzmin\"] = neatMSPeakList[\"mzmed\"].values - (ms1ppm * neatMSPeakList[\"mzmed\"].values) / 1e6\n",
    "neatMSPeakList[\"mzmax\"] = neatMSPeakList[\"mzmed\"].values + (ms1ppm * neatMSPeakList[\"mzmed\"].values) / 1e6\n",
    "neatMSPeakList[\"intb\"] = neatMSPeakList[\"into\"].values\n",
    "neatMSPeakList[\"maxo\"] = neatMSPeakList[\"into\"].values\n",
    "neatMSPeakList[\"sn\"] = [10 for _ in range(len(neatMSPeakList))]\n",
    "neatMSPeakList[\"sample_name\"] = neatMSPeakList[\"sample\"].values\n",
    "neatMSPeakList[\"rtmin\"] = neatMSPeakList[\"rtmin\"].values - .2 * 60\n",
    "neatMSPeakList[\"rtmax\"] = neatMSPeakList[\"rtmin\"].values + .2 * 60\n",
    "neatMSPeakList = neatMSPeakList.rename({\"mzmed\":\"mz\",\"rtmed\":\"rt\"},axis=1)\n",
    "\n",
    "neatMSPeakList.to_csv(datadir + \"neatms_peak_list.csv\",index=False)\n",
    "neatMSPeakList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table_path = datadir+\"neatms_peak_list.csv\"\n",
    "input_data = 'xcms'\n",
    "experiment = ntms.Experiment(rawDataDir, feature_table_path, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler = ntms.NN_handler(experiment,min_scan_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2, 120, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 2, 120, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 60, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 60, 64)         18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 7680)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               983168    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_prediction (Dense)    (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,002,883\n",
      "Trainable params: 1,002,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../data/neatms/neatms_default_model.h5\"\n",
    "nn_handler.create_model(model = model_path)\n",
    "nn_handler.get_model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 1s 6ms/step\n",
      "127/127 [==============================] - 1s 6ms/step\n",
      "126/126 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Set the threshold to 0.22\n",
    "threshold=0.22\n",
    "# Run the prediction\n",
    "nn_handler.predict_peaks(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>m/z</th>\n",
       "      <th>retention time</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4189</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>54.977012</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>153221.001212</td>\n",
       "      <td>153221.001212</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4189</td>\n",
       "      <td>B1_NIST1950_2_6540</td>\n",
       "      <td>54.977012</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>121049.319269</td>\n",
       "      <td>121049.319269</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4189</td>\n",
       "      <td>B1_NIST1950_3_6540</td>\n",
       "      <td>54.977012</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>121518.648674</td>\n",
       "      <td>121518.648674</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4190</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>55.018832</td>\n",
       "      <td>6.038233</td>\n",
       "      <td>6447.719840</td>\n",
       "      <td>6447.719840</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4190</td>\n",
       "      <td>B1_NIST1950_2_6540</td>\n",
       "      <td>55.018832</td>\n",
       "      <td>6.038233</td>\n",
       "      <td>9208.601970</td>\n",
       "      <td>9208.601970</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>8374</td>\n",
       "      <td>B1_NIST1950_2_6540</td>\n",
       "      <td>1613.977307</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>49999.415489</td>\n",
       "      <td>49999.415489</td>\n",
       "      <td>High_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12093</th>\n",
       "      <td>8374</td>\n",
       "      <td>B1_NIST1950_3_6540</td>\n",
       "      <td>1613.977307</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>23885.945518</td>\n",
       "      <td>23885.945518</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12094</th>\n",
       "      <td>8375</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1613.978958</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>13252.754702</td>\n",
       "      <td>13252.754702</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12095</th>\n",
       "      <td>8375</td>\n",
       "      <td>B1_NIST1950_2_6540</td>\n",
       "      <td>1613.978958</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>15256.555134</td>\n",
       "      <td>15256.555134</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12096</th>\n",
       "      <td>8375</td>\n",
       "      <td>B1_NIST1950_3_6540</td>\n",
       "      <td>1613.978958</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>22642.497262</td>\n",
       "      <td>22642.497262</td>\n",
       "      <td>High_quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12097 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature ID              sample          m/z  retention time  \\\n",
       "0            4189  B1_NIST1950_1_6540    54.977012        5.074017   \n",
       "1            4189  B1_NIST1950_2_6540    54.977012        5.074017   \n",
       "2            4189  B1_NIST1950_3_6540    54.977012        5.074017   \n",
       "3            4190  B1_NIST1950_1_6540    55.018832        6.038233   \n",
       "4            4190  B1_NIST1950_2_6540    55.018832        6.038233   \n",
       "...           ...                 ...          ...             ...   \n",
       "12092        8374  B1_NIST1950_2_6540  1613.977307       14.982067   \n",
       "12093        8374  B1_NIST1950_3_6540  1613.977307       14.982067   \n",
       "12094        8375  B1_NIST1950_1_6540  1613.978958       12.721182   \n",
       "12095        8375  B1_NIST1950_2_6540  1613.978958       12.721182   \n",
       "12096        8375  B1_NIST1950_3_6540  1613.978958       12.721182   \n",
       "\n",
       "              height           area         label  \n",
       "0      153221.001212  153221.001212         Noise  \n",
       "1      121049.319269  121049.319269         Noise  \n",
       "2      121518.648674  121518.648674         Noise  \n",
       "3        6447.719840    6447.719840         Noise  \n",
       "4        9208.601970    9208.601970         Noise  \n",
       "...              ...            ...           ...  \n",
       "12092   49999.415489   49999.415489  High_quality  \n",
       "12093   23885.945518   23885.945518         Noise  \n",
       "12094   13252.754702   13252.754702         Noise  \n",
       "12095   15256.555134   15256.555134         Noise  \n",
       "12096   22642.497262   22642.497262  High_quality  \n",
       "\n",
       "[12097 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create the dataframe using this function\n",
    "NeatMS_output_df = experiment.export_to_dataframe()\n",
    "# And display it\n",
    "NeatMS_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X,X_labeled,y_labeled,X_syn,y_syn] = pkl.load(open(datadir+\"model_selection_data.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "[peaks_test,X_val,y_val,X_test,y_test,X_labeled,y_labeled] = pkl.load(open(datadir+\"eval_data.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>m/z</th>\n",
       "      <th>retention time</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4189</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>54.977012</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>1.532210e+05</td>\n",
       "      <td>1.532210e+05</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4190</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>55.018832</td>\n",
       "      <td>6.038233</td>\n",
       "      <td>6.447720e+03</td>\n",
       "      <td>6.447720e+03</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4191</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>56.995900</td>\n",
       "      <td>13.086900</td>\n",
       "      <td>6.127502e+06</td>\n",
       "      <td>6.127502e+06</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4192</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>57.034581</td>\n",
       "      <td>1.590991</td>\n",
       "      <td>3.627522e+04</td>\n",
       "      <td>3.627522e+04</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4193</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>57.028878</td>\n",
       "      <td>12.804283</td>\n",
       "      <td>2.734232e+03</td>\n",
       "      <td>2.734232e+03</td>\n",
       "      <td>High_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>8371</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1612.974722</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>1.910637e+04</td>\n",
       "      <td>1.910637e+04</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085</th>\n",
       "      <td>8372</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1612.976154</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>1.358256e+04</td>\n",
       "      <td>1.358256e+04</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>8373</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1613.978101</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>3.174946e+03</td>\n",
       "      <td>3.174946e+03</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12091</th>\n",
       "      <td>8374</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1613.977307</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>2.855932e+04</td>\n",
       "      <td>2.855932e+04</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12094</th>\n",
       "      <td>8375</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1613.978958</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>1.325275e+04</td>\n",
       "      <td>1.325275e+04</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4034 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature ID              sample          m/z  retention time  \\\n",
       "0            4189  B1_NIST1950_1_6540    54.977012        5.074017   \n",
       "3            4190  B1_NIST1950_1_6540    55.018832        6.038233   \n",
       "6            4191  B1_NIST1950_1_6540    56.995900       13.086900   \n",
       "9            4192  B1_NIST1950_1_6540    57.034581        1.590991   \n",
       "12           4193  B1_NIST1950_1_6540    57.028878       12.804283   \n",
       "...           ...                 ...          ...             ...   \n",
       "12082        8371  B1_NIST1950_1_6540  1612.974722        2.214650   \n",
       "12085        8372  B1_NIST1950_1_6540  1612.976154       14.982067   \n",
       "12088        8373  B1_NIST1950_1_6540  1613.978101        2.214650   \n",
       "12091        8374  B1_NIST1950_1_6540  1613.977307       14.982067   \n",
       "12094        8375  B1_NIST1950_1_6540  1613.978958       12.721182   \n",
       "\n",
       "             height          area         label  \n",
       "0      1.532210e+05  1.532210e+05         Noise  \n",
       "3      6.447720e+03  6.447720e+03         Noise  \n",
       "6      6.127502e+06  6.127502e+06         Noise  \n",
       "9      3.627522e+04  3.627522e+04         Noise  \n",
       "12     2.734232e+03  2.734232e+03  High_quality  \n",
       "...             ...           ...           ...  \n",
       "12082  1.910637e+04  1.910637e+04         Noise  \n",
       "12085  1.358256e+04  1.358256e+04         Noise  \n",
       "12088  3.174946e+03  3.174946e+03         Noise  \n",
       "12091  2.855932e+04  2.855932e+04         Noise  \n",
       "12094  1.325275e+04  1.325275e+04         Noise  \n",
       "\n",
       "[4034 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = NeatMS_output_df[NeatMS_output_df[\"sample\"] == files[0].replace(\".mzML\",\"\")]\n",
    "filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "matchIDs = {}\n",
    "for index,row in peaks_test.iterrows():\n",
    "    for index2,row2 in filt.iterrows():\n",
    "        if row2[\"m/z\"] > row[\"mz\"] + 0.001:\n",
    "            break\n",
    "        if np.abs(row[\"rt\"] - row2[\"retention time\"]) < 0.03:\n",
    "            if np.abs(row[\"mz\"] - row2[\"m/z\"]) < 0.001:\n",
    "                matchIDs[index] = index2\n",
    "                break\n",
    "print(len(matchIDs))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>m/z</th>\n",
       "      <th>retention time</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>label</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10717</th>\n",
       "      <td>7907</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>638.103711</td>\n",
       "      <td>0.724168</td>\n",
       "      <td>6050.758047</td>\n",
       "      <td>6050.758047</td>\n",
       "      <td>High_quality</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4403</th>\n",
       "      <td>5713</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>254.624195</td>\n",
       "      <td>0.834850</td>\n",
       "      <td>98824.035679</td>\n",
       "      <td>98824.035679</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10846</th>\n",
       "      <td>7953</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>666.784066</td>\n",
       "      <td>13.086900</td>\n",
       "      <td>8112.694799</td>\n",
       "      <td>8112.694799</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>5938</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>275.202386</td>\n",
       "      <td>0.851467</td>\n",
       "      <td>46051.935219</td>\n",
       "      <td>46051.935219</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>7112</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>442.265574</td>\n",
       "      <td>0.984468</td>\n",
       "      <td>6923.086015</td>\n",
       "      <td>6923.086015</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>5659</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>249.975378</td>\n",
       "      <td>9.047198</td>\n",
       "      <td>323861.620950</td>\n",
       "      <td>323861.620950</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9940</th>\n",
       "      <td>7636</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>550.455573</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>22174.686775</td>\n",
       "      <td>22174.686775</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10735</th>\n",
       "      <td>7913</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>640.129377</td>\n",
       "      <td>0.917967</td>\n",
       "      <td>8536.802503</td>\n",
       "      <td>8536.802503</td>\n",
       "      <td>High_quality</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>6508</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>340.236364</td>\n",
       "      <td>0.934592</td>\n",
       "      <td>79630.589056</td>\n",
       "      <td>79630.589056</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>6003</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>283.064220</td>\n",
       "      <td>6.154736</td>\n",
       "      <td>2902.056490</td>\n",
       "      <td>2902.056490</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature ID              sample         m/z  retention time  \\\n",
       "10717        7907  B1_NIST1950_1_6540  638.103711        0.724168   \n",
       "4403         5713  B1_NIST1950_1_6540  254.624195        0.834850   \n",
       "10846        7953  B1_NIST1950_1_6540  666.784066       13.086900   \n",
       "5069         5938  B1_NIST1950_1_6540  275.202386        0.851467   \n",
       "8450         7112  B1_NIST1950_1_6540  442.265574        0.984468   \n",
       "...           ...                 ...         ...             ...   \n",
       "4241         5659  B1_NIST1950_1_6540  249.975378        9.047198   \n",
       "9940         7636  B1_NIST1950_1_6540  550.455573        0.784983   \n",
       "10735        7913  B1_NIST1950_1_6540  640.129377        0.917967   \n",
       "6710         6508  B1_NIST1950_1_6540  340.236364        0.934592   \n",
       "5259         6003  B1_NIST1950_1_6540  283.064220        6.154736   \n",
       "\n",
       "              height           area         label  classification  \n",
       "10717    6050.758047    6050.758047  High_quality             1.0  \n",
       "4403    98824.035679   98824.035679         Noise             0.0  \n",
       "10846    8112.694799    8112.694799         Noise             0.0  \n",
       "5069    46051.935219   46051.935219         Noise             0.0  \n",
       "8450     6923.086015    6923.086015         Noise             0.0  \n",
       "...              ...            ...           ...             ...  \n",
       "4241   323861.620950  323861.620950         Noise             0.0  \n",
       "9940    22174.686775   22174.686775         Noise             0.0  \n",
       "10735    8536.802503    8536.802503  High_quality             1.0  \n",
       "6710    79630.589056   79630.589056         Noise             0.0  \n",
       "5259     2902.056490    2902.056490         Noise             0.0  \n",
       "\n",
       "[147 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = list(matchIDs.keys())\n",
    "filt = filt.loc[[matchIDs[x] for x in order],:]\n",
    "classification = []\n",
    "for index,row in filt.iterrows():\n",
    "    if row[\"label\"] == \"High_quality\":\n",
    "        classification.append(1.0)\n",
    "    elif row[\"label\"] == \"Low_quality\":\n",
    "        classification.append(0.5)\n",
    "    else:\n",
    "        classification.append(0.0)\n",
    "filt[\"classification\"] = classification\n",
    "filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[order]\n",
    "y_test = y_test[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scores_neat_ms = filt[\"classification\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ethan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\NeatMS\\annotation.py:175: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "c:\\users\\ethan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\NeatMS\\annotation.py:176: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1fc88984a88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotation_tool = ntms.AnnotationTool(experiment)\n",
    "annotation_tool.launch_annotation_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of annotated peaks: 411\n",
      "High_quality 102\n",
      "Low_quality 55\n",
      "Noise 254\n"
     ]
    }
   ],
   "source": [
    "annotation_table = experiment.feature_tables[0].annotation_table\n",
    "print(\"Total number of annotated peaks:\",len(annotation_table.labelled_peaks))\n",
    "for annotation in annotation_table.annotations:\n",
    "    print(annotation.label,len(annotation.peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.name = datadir + \"TL_neatms_model411\"\n",
    "experiment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = datadir + \"TL_neatms_model411.pkl\"\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    experiment = pkl.load(f)\n",
    "nn_handler = ntms.NN_handler(experiment,min_scan_num=0)\n",
    "model_path = \"../data/neatms/neatms_default_model.h5\"\n",
    "nn_handler.create_model(model = model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x0000025F04B9AD88> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000025F04B9B588> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000025F068B0D08> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000025F04B9D8C8> False\n",
      "<keras.layers.reshaping.flatten.Flatten object at 0x0000025ECB1C0B08> True\n",
      "<keras.layers.core.dense.Dense object at 0x0000025F04514808> True\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x0000025F04B9E088> True\n",
      "<keras.layers.core.dense.Dense object at 0x0000025F04B9EA48> True\n"
     ]
    }
   ],
   "source": [
    "# Let's freeze the convolutional base\n",
    "# We can do that by selecting layers using their names\n",
    "\n",
    "layer_names = ['conv2d_1','conv2d_2','max_pooling2d_1']\n",
    "for layer_name in layer_names:\n",
    "    nn_handler.class_model.get_layer(layer_name).trainable = False\n",
    "\n",
    "# Here is how to make sure that the right layers are still trainable\n",
    "for layer in nn_handler.class_model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ethan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, Adam \n",
    "lr = 0.00001\n",
    "opt = Adam(lr=lr)\n",
    "nn_handler.class_model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy','mae'])\n",
    "\n",
    "nn_handler.create_batches(validation_split=0.1, normalise_class=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 1s 43ms/step - loss: 2.1455 - accuracy: 0.4635 - mae: 0.3580 - val_loss: 1.5974 - val_accuracy: 0.5750 - val_mae: 0.3106\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.0639 - accuracy: 0.4667 - mae: 0.3667 - val_loss: 1.4997 - val_accuracy: 0.5750 - val_mae: 0.3138\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.9673 - accuracy: 0.4635 - mae: 0.3675 - val_loss: 1.4166 - val_accuracy: 0.5000 - val_mae: 0.3165\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.8634 - accuracy: 0.4667 - mae: 0.3616 - val_loss: 1.3557 - val_accuracy: 0.5000 - val_mae: 0.3180\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.8223 - accuracy: 0.4222 - mae: 0.3750 - val_loss: 1.3104 - val_accuracy: 0.5000 - val_mae: 0.3189\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.7635 - accuracy: 0.4286 - mae: 0.3702 - val_loss: 1.2755 - val_accuracy: 0.5000 - val_mae: 0.3191\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.7622 - accuracy: 0.4698 - mae: 0.3739 - val_loss: 1.2440 - val_accuracy: 0.5000 - val_mae: 0.3188\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.6693 - accuracy: 0.4730 - mae: 0.3604 - val_loss: 1.2149 - val_accuracy: 0.5000 - val_mae: 0.3187\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.6744 - accuracy: 0.4794 - mae: 0.3699 - val_loss: 1.1884 - val_accuracy: 0.5000 - val_mae: 0.3192\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.6275 - accuracy: 0.4698 - mae: 0.3681 - val_loss: 1.1658 - val_accuracy: 0.5000 - val_mae: 0.3191\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4762 - accuracy: 0.4571 - mae: 0.3639 - val_loss: 1.1432 - val_accuracy: 0.5000 - val_mae: 0.3187\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5168 - accuracy: 0.4730 - mae: 0.3648 - val_loss: 1.1228 - val_accuracy: 0.5000 - val_mae: 0.3176\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5461 - accuracy: 0.4476 - mae: 0.3753 - val_loss: 1.1009 - val_accuracy: 0.5000 - val_mae: 0.3169\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.3591 - accuracy: 0.5048 - mae: 0.3521 - val_loss: 1.0785 - val_accuracy: 0.5000 - val_mae: 0.3166\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4057 - accuracy: 0.4921 - mae: 0.3528 - val_loss: 1.0578 - val_accuracy: 0.5250 - val_mae: 0.3154\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3786 - accuracy: 0.4794 - mae: 0.3556 - val_loss: 1.0370 - val_accuracy: 0.5250 - val_mae: 0.3150\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3317 - accuracy: 0.4762 - mae: 0.3526 - val_loss: 1.0164 - val_accuracy: 0.5250 - val_mae: 0.3150\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.2901 - accuracy: 0.4730 - mae: 0.3554 - val_loss: 0.9993 - val_accuracy: 0.5250 - val_mae: 0.3148\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2344 - accuracy: 0.4444 - mae: 0.3562 - val_loss: 0.9832 - val_accuracy: 0.5250 - val_mae: 0.3143\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.2179 - accuracy: 0.4889 - mae: 0.3428 - val_loss: 0.9687 - val_accuracy: 0.5500 - val_mae: 0.3129\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2155 - accuracy: 0.4984 - mae: 0.3494 - val_loss: 0.9536 - val_accuracy: 0.5500 - val_mae: 0.3125\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2033 - accuracy: 0.4889 - mae: 0.3519 - val_loss: 0.9398 - val_accuracy: 0.5500 - val_mae: 0.3128\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.1705 - accuracy: 0.5206 - mae: 0.3455 - val_loss: 0.9254 - val_accuracy: 0.5750 - val_mae: 0.3119\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1271 - accuracy: 0.5206 - mae: 0.3461 - val_loss: 0.9107 - val_accuracy: 0.5750 - val_mae: 0.3115\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0858 - accuracy: 0.5365 - mae: 0.3384 - val_loss: 0.8972 - val_accuracy: 0.5750 - val_mae: 0.3099\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0801 - accuracy: 0.5365 - mae: 0.3359 - val_loss: 0.8845 - val_accuracy: 0.6250 - val_mae: 0.3084\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0882 - accuracy: 0.5651 - mae: 0.3322 - val_loss: 0.8725 - val_accuracy: 0.6250 - val_mae: 0.3070\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0883 - accuracy: 0.5206 - mae: 0.3384 - val_loss: 0.8635 - val_accuracy: 0.6250 - val_mae: 0.3071\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0657 - accuracy: 0.5778 - mae: 0.3353 - val_loss: 0.8559 - val_accuracy: 0.6250 - val_mae: 0.3071\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0255 - accuracy: 0.5968 - mae: 0.3302 - val_loss: 0.8488 - val_accuracy: 0.6500 - val_mae: 0.3073\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0324 - accuracy: 0.5587 - mae: 0.3359 - val_loss: 0.8413 - val_accuracy: 0.6500 - val_mae: 0.3058\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.9815 - accuracy: 0.5873 - mae: 0.3249 - val_loss: 0.8343 - val_accuracy: 0.6750 - val_mae: 0.3046\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9709 - accuracy: 0.5651 - mae: 0.3278 - val_loss: 0.8272 - val_accuracy: 0.6750 - val_mae: 0.3033\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9934 - accuracy: 0.5841 - mae: 0.3262 - val_loss: 0.8214 - val_accuracy: 0.7000 - val_mae: 0.3030\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0009 - accuracy: 0.6190 - mae: 0.3302 - val_loss: 0.8165 - val_accuracy: 0.7000 - val_mae: 0.3045\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9695 - accuracy: 0.6063 - mae: 0.3216 - val_loss: 0.8127 - val_accuracy: 0.7000 - val_mae: 0.3048\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9872 - accuracy: 0.6222 - mae: 0.3279 - val_loss: 0.8091 - val_accuracy: 0.7000 - val_mae: 0.3054\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9527 - accuracy: 0.5905 - mae: 0.3277 - val_loss: 0.8048 - val_accuracy: 0.7000 - val_mae: 0.3049\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9500 - accuracy: 0.6222 - mae: 0.3205 - val_loss: 0.8010 - val_accuracy: 0.7000 - val_mae: 0.3042\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9356 - accuracy: 0.6159 - mae: 0.3171 - val_loss: 0.7977 - val_accuracy: 0.7000 - val_mae: 0.3039\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9182 - accuracy: 0.6286 - mae: 0.3180 - val_loss: 0.7943 - val_accuracy: 0.6750 - val_mae: 0.3017\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9143 - accuracy: 0.6317 - mae: 0.3158 - val_loss: 0.7908 - val_accuracy: 0.6500 - val_mae: 0.3007\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9091 - accuracy: 0.6508 - mae: 0.3151 - val_loss: 0.7870 - val_accuracy: 0.6500 - val_mae: 0.2999\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.9448 - accuracy: 0.6159 - mae: 0.3204 - val_loss: 0.7845 - val_accuracy: 0.6500 - val_mae: 0.2988\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.9213 - accuracy: 0.6381 - mae: 0.3176 - val_loss: 0.7816 - val_accuracy: 0.6500 - val_mae: 0.2988\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8798 - accuracy: 0.6349 - mae: 0.3139 - val_loss: 0.7785 - val_accuracy: 0.6500 - val_mae: 0.2989\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9050 - accuracy: 0.6254 - mae: 0.3135 - val_loss: 0.7755 - val_accuracy: 0.6500 - val_mae: 0.2980\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9077 - accuracy: 0.6381 - mae: 0.3153 - val_loss: 0.7732 - val_accuracy: 0.6500 - val_mae: 0.2976\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9000 - accuracy: 0.6032 - mae: 0.3167 - val_loss: 0.7706 - val_accuracy: 0.6500 - val_mae: 0.2974\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9005 - accuracy: 0.6381 - mae: 0.3137 - val_loss: 0.7685 - val_accuracy: 0.6750 - val_mae: 0.2959\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8887 - accuracy: 0.6444 - mae: 0.3149 - val_loss: 0.7673 - val_accuracy: 0.6750 - val_mae: 0.2971\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.9046 - accuracy: 0.6317 - mae: 0.3205 - val_loss: 0.7652 - val_accuracy: 0.6750 - val_mae: 0.2962\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8720 - accuracy: 0.6730 - mae: 0.3099 - val_loss: 0.7631 - val_accuracy: 0.6750 - val_mae: 0.2959\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8340 - accuracy: 0.6730 - mae: 0.2990 - val_loss: 0.7612 - val_accuracy: 0.6750 - val_mae: 0.2948\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.8504 - accuracy: 0.6857 - mae: 0.3048 - val_loss: 0.7599 - val_accuracy: 0.6750 - val_mae: 0.2951\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8717 - accuracy: 0.6540 - mae: 0.3088 - val_loss: 0.7588 - val_accuracy: 0.6750 - val_mae: 0.2959\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8741 - accuracy: 0.6571 - mae: 0.3109 - val_loss: 0.7573 - val_accuracy: 0.6750 - val_mae: 0.2955\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8513 - accuracy: 0.6667 - mae: 0.3029 - val_loss: 0.7562 - val_accuracy: 0.7000 - val_mae: 0.2956\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8543 - accuracy: 0.6698 - mae: 0.3059 - val_loss: 0.7558 - val_accuracy: 0.7000 - val_mae: 0.2961\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8389 - accuracy: 0.6825 - mae: 0.3070 - val_loss: 0.7546 - val_accuracy: 0.7000 - val_mae: 0.2956\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.8352 - accuracy: 0.6984 - mae: 0.3015 - val_loss: 0.7525 - val_accuracy: 0.6750 - val_mae: 0.2938\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8370 - accuracy: 0.6762 - mae: 0.3019 - val_loss: 0.7515 - val_accuracy: 0.6750 - val_mae: 0.2930\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8294 - accuracy: 0.7111 - mae: 0.2978 - val_loss: 0.7504 - val_accuracy: 0.6750 - val_mae: 0.2936\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8454 - accuracy: 0.6444 - mae: 0.3062 - val_loss: 0.7483 - val_accuracy: 0.6750 - val_mae: 0.2929\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8550 - accuracy: 0.6635 - mae: 0.3069 - val_loss: 0.7475 - val_accuracy: 0.6750 - val_mae: 0.2922\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8062 - accuracy: 0.7079 - mae: 0.2970 - val_loss: 0.7464 - val_accuracy: 0.6750 - val_mae: 0.2924\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8331 - accuracy: 0.6571 - mae: 0.3015 - val_loss: 0.7456 - val_accuracy: 0.6750 - val_mae: 0.2922\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8222 - accuracy: 0.6667 - mae: 0.2982 - val_loss: 0.7440 - val_accuracy: 0.7000 - val_mae: 0.2921\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8146 - accuracy: 0.6698 - mae: 0.2993 - val_loss: 0.7431 - val_accuracy: 0.7000 - val_mae: 0.2929\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.8218 - accuracy: 0.6825 - mae: 0.2960 - val_loss: 0.7416 - val_accuracy: 0.7000 - val_mae: 0.2924\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8246 - accuracy: 0.6730 - mae: 0.3002 - val_loss: 0.7405 - val_accuracy: 0.7000 - val_mae: 0.2924\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7896 - accuracy: 0.6921 - mae: 0.2926 - val_loss: 0.7396 - val_accuracy: 0.7000 - val_mae: 0.2915\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8114 - accuracy: 0.7016 - mae: 0.2950 - val_loss: 0.7376 - val_accuracy: 0.6750 - val_mae: 0.2893\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7869 - accuracy: 0.6952 - mae: 0.2891 - val_loss: 0.7375 - val_accuracy: 0.7000 - val_mae: 0.2905\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8125 - accuracy: 0.6984 - mae: 0.2982 - val_loss: 0.7367 - val_accuracy: 0.7000 - val_mae: 0.2908\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7958 - accuracy: 0.6921 - mae: 0.2963 - val_loss: 0.7357 - val_accuracy: 0.7000 - val_mae: 0.2913\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7822 - accuracy: 0.7016 - mae: 0.2903 - val_loss: 0.7335 - val_accuracy: 0.7000 - val_mae: 0.2896\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7859 - accuracy: 0.6889 - mae: 0.2914 - val_loss: 0.7326 - val_accuracy: 0.7000 - val_mae: 0.2889\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8033 - accuracy: 0.6825 - mae: 0.2983 - val_loss: 0.7312 - val_accuracy: 0.7000 - val_mae: 0.2881\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7912 - accuracy: 0.7079 - mae: 0.2911 - val_loss: 0.7300 - val_accuracy: 0.7000 - val_mae: 0.2868\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8001 - accuracy: 0.6794 - mae: 0.2932 - val_loss: 0.7289 - val_accuracy: 0.7000 - val_mae: 0.2865\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8130 - accuracy: 0.6857 - mae: 0.2931 - val_loss: 0.7281 - val_accuracy: 0.7000 - val_mae: 0.2869\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8045 - accuracy: 0.6857 - mae: 0.2942 - val_loss: 0.7290 - val_accuracy: 0.6750 - val_mae: 0.2889\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7945 - accuracy: 0.7016 - mae: 0.2963 - val_loss: 0.7278 - val_accuracy: 0.7000 - val_mae: 0.2882\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7837 - accuracy: 0.6857 - mae: 0.2930 - val_loss: 0.7260 - val_accuracy: 0.7000 - val_mae: 0.2860\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8061 - accuracy: 0.6857 - mae: 0.2951 - val_loss: 0.7253 - val_accuracy: 0.7000 - val_mae: 0.2852\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7864 - accuracy: 0.6984 - mae: 0.2888 - val_loss: 0.7244 - val_accuracy: 0.7000 - val_mae: 0.2839\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7873 - accuracy: 0.7206 - mae: 0.2903 - val_loss: 0.7250 - val_accuracy: 0.7000 - val_mae: 0.2853\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7752 - accuracy: 0.7111 - mae: 0.2876 - val_loss: 0.7247 - val_accuracy: 0.7000 - val_mae: 0.2863\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8063 - accuracy: 0.7016 - mae: 0.2949 - val_loss: 0.7237 - val_accuracy: 0.7000 - val_mae: 0.2858\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7755 - accuracy: 0.7238 - mae: 0.2875 - val_loss: 0.7224 - val_accuracy: 0.7250 - val_mae: 0.2852\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8025 - accuracy: 0.6984 - mae: 0.2933 - val_loss: 0.7211 - val_accuracy: 0.7000 - val_mae: 0.2837\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7969 - accuracy: 0.7111 - mae: 0.2901 - val_loss: 0.7212 - val_accuracy: 0.7250 - val_mae: 0.2849\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7756 - accuracy: 0.6984 - mae: 0.2897 - val_loss: 0.7214 - val_accuracy: 0.7000 - val_mae: 0.2856\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7937 - accuracy: 0.6984 - mae: 0.2921 - val_loss: 0.7202 - val_accuracy: 0.7250 - val_mae: 0.2842\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7686 - accuracy: 0.7175 - mae: 0.2845 - val_loss: 0.7190 - val_accuracy: 0.7000 - val_mae: 0.2834\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7725 - accuracy: 0.7206 - mae: 0.2889 - val_loss: 0.7182 - val_accuracy: 0.7250 - val_mae: 0.2835\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7825 - accuracy: 0.7302 - mae: 0.2858 - val_loss: 0.7179 - val_accuracy: 0.7000 - val_mae: 0.2841\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7709 - accuracy: 0.7175 - mae: 0.2897 - val_loss: 0.7156 - val_accuracy: 0.7250 - val_mae: 0.2828\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7551 - accuracy: 0.7175 - mae: 0.2819 - val_loss: 0.7155 - val_accuracy: 0.7000 - val_mae: 0.2829\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7682 - accuracy: 0.7079 - mae: 0.2814 - val_loss: 0.7142 - val_accuracy: 0.7250 - val_mae: 0.2820\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7522 - accuracy: 0.7079 - mae: 0.2812 - val_loss: 0.7134 - val_accuracy: 0.7250 - val_mae: 0.2818\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7800 - accuracy: 0.7143 - mae: 0.2889 - val_loss: 0.7131 - val_accuracy: 0.7000 - val_mae: 0.2820\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7666 - accuracy: 0.7079 - mae: 0.2834 - val_loss: 0.7129 - val_accuracy: 0.7000 - val_mae: 0.2820\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7876 - accuracy: 0.7048 - mae: 0.2900 - val_loss: 0.7124 - val_accuracy: 0.7000 - val_mae: 0.2823\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7762 - accuracy: 0.7175 - mae: 0.2895 - val_loss: 0.7117 - val_accuracy: 0.7250 - val_mae: 0.2812\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7819 - accuracy: 0.6984 - mae: 0.2865 - val_loss: 0.7114 - val_accuracy: 0.7250 - val_mae: 0.2812\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7777 - accuracy: 0.7079 - mae: 0.2858 - val_loss: 0.7121 - val_accuracy: 0.7000 - val_mae: 0.2827\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7421 - accuracy: 0.7143 - mae: 0.2825 - val_loss: 0.7111 - val_accuracy: 0.7000 - val_mae: 0.2821\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7424 - accuracy: 0.7333 - mae: 0.2759 - val_loss: 0.7104 - val_accuracy: 0.7000 - val_mae: 0.2819\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7545 - accuracy: 0.7016 - mae: 0.2827 - val_loss: 0.7099 - val_accuracy: 0.7000 - val_mae: 0.2819\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7652 - accuracy: 0.7143 - mae: 0.2865 - val_loss: 0.7100 - val_accuracy: 0.7000 - val_mae: 0.2816\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7762 - accuracy: 0.7016 - mae: 0.2853 - val_loss: 0.7097 - val_accuracy: 0.7500 - val_mae: 0.2806\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7252 - accuracy: 0.7302 - mae: 0.2782 - val_loss: 0.7089 - val_accuracy: 0.7500 - val_mae: 0.2799\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7610 - accuracy: 0.7206 - mae: 0.2827 - val_loss: 0.7083 - val_accuracy: 0.7250 - val_mae: 0.2796\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7453 - accuracy: 0.7143 - mae: 0.2811 - val_loss: 0.7077 - val_accuracy: 0.7500 - val_mae: 0.2793\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7355 - accuracy: 0.7238 - mae: 0.2774 - val_loss: 0.7074 - val_accuracy: 0.7250 - val_mae: 0.2800\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7568 - accuracy: 0.7143 - mae: 0.2843 - val_loss: 0.7061 - val_accuracy: 0.7000 - val_mae: 0.2799\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7601 - accuracy: 0.7175 - mae: 0.2838 - val_loss: 0.7045 - val_accuracy: 0.7250 - val_mae: 0.2784\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7614 - accuracy: 0.7270 - mae: 0.2810 - val_loss: 0.7041 - val_accuracy: 0.7250 - val_mae: 0.2787\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7520 - accuracy: 0.7175 - mae: 0.2788 - val_loss: 0.7035 - val_accuracy: 0.7250 - val_mae: 0.2779\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7633 - accuracy: 0.6857 - mae: 0.2837 - val_loss: 0.7029 - val_accuracy: 0.7250 - val_mae: 0.2784\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7552 - accuracy: 0.7111 - mae: 0.2812 - val_loss: 0.7036 - val_accuracy: 0.7250 - val_mae: 0.2794\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7319 - accuracy: 0.7429 - mae: 0.2781 - val_loss: 0.7026 - val_accuracy: 0.7250 - val_mae: 0.2793\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7405 - accuracy: 0.7397 - mae: 0.2761 - val_loss: 0.7010 - val_accuracy: 0.7250 - val_mae: 0.2784\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7510 - accuracy: 0.7238 - mae: 0.2807 - val_loss: 0.6988 - val_accuracy: 0.7250 - val_mae: 0.2770\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7500 - accuracy: 0.7206 - mae: 0.2777 - val_loss: 0.6978 - val_accuracy: 0.7250 - val_mae: 0.2757\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7414 - accuracy: 0.7206 - mae: 0.2761 - val_loss: 0.6978 - val_accuracy: 0.7250 - val_mae: 0.2760\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7417 - accuracy: 0.7143 - mae: 0.2748 - val_loss: 0.6984 - val_accuracy: 0.7250 - val_mae: 0.2772\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7449 - accuracy: 0.7206 - mae: 0.2751 - val_loss: 0.6990 - val_accuracy: 0.7500 - val_mae: 0.2780\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7390 - accuracy: 0.7270 - mae: 0.2807 - val_loss: 0.6982 - val_accuracy: 0.7500 - val_mae: 0.2774\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7391 - accuracy: 0.7238 - mae: 0.2779 - val_loss: 0.6960 - val_accuracy: 0.7250 - val_mae: 0.2760\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7797 - accuracy: 0.7111 - mae: 0.2837 - val_loss: 0.6968 - val_accuracy: 0.7250 - val_mae: 0.2765\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7380 - accuracy: 0.7270 - mae: 0.2775 - val_loss: 0.6969 - val_accuracy: 0.7250 - val_mae: 0.2765\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7265 - accuracy: 0.7365 - mae: 0.2739 - val_loss: 0.6964 - val_accuracy: 0.7250 - val_mae: 0.2764\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7349 - accuracy: 0.7238 - mae: 0.2786 - val_loss: 0.6958 - val_accuracy: 0.7500 - val_mae: 0.2763\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7427 - accuracy: 0.7333 - mae: 0.2778 - val_loss: 0.6956 - val_accuracy: 0.7500 - val_mae: 0.2766\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7376 - accuracy: 0.7492 - mae: 0.2775 - val_loss: 0.6940 - val_accuracy: 0.7250 - val_mae: 0.2754\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7135 - accuracy: 0.7333 - mae: 0.2728 - val_loss: 0.6936 - val_accuracy: 0.7250 - val_mae: 0.2753\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7228 - accuracy: 0.7587 - mae: 0.2723 - val_loss: 0.6920 - val_accuracy: 0.7250 - val_mae: 0.2738\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7481 - accuracy: 0.7175 - mae: 0.2819 - val_loss: 0.6922 - val_accuracy: 0.7250 - val_mae: 0.2741\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7491 - accuracy: 0.7238 - mae: 0.2800 - val_loss: 0.6931 - val_accuracy: 0.7500 - val_mae: 0.2752\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7215 - accuracy: 0.7556 - mae: 0.2734 - val_loss: 0.6911 - val_accuracy: 0.7250 - val_mae: 0.2742\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7333 - accuracy: 0.7302 - mae: 0.2781 - val_loss: 0.6896 - val_accuracy: 0.7250 - val_mae: 0.2735\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7342 - accuracy: 0.7238 - mae: 0.2758 - val_loss: 0.6905 - val_accuracy: 0.7500 - val_mae: 0.2740\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7357 - accuracy: 0.7587 - mae: 0.2724 - val_loss: 0.6898 - val_accuracy: 0.7500 - val_mae: 0.2733\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7173 - accuracy: 0.7556 - mae: 0.2723 - val_loss: 0.6900 - val_accuracy: 0.7500 - val_mae: 0.2739\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7265 - accuracy: 0.7429 - mae: 0.2782 - val_loss: 0.6894 - val_accuracy: 0.7500 - val_mae: 0.2735\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7438 - accuracy: 0.7270 - mae: 0.2775 - val_loss: 0.6877 - val_accuracy: 0.7500 - val_mae: 0.2728\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7251 - accuracy: 0.7460 - mae: 0.2734 - val_loss: 0.6866 - val_accuracy: 0.7250 - val_mae: 0.2718\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7323 - accuracy: 0.7492 - mae: 0.2770 - val_loss: 0.6869 - val_accuracy: 0.7500 - val_mae: 0.2723\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7047 - accuracy: 0.7524 - mae: 0.2699 - val_loss: 0.6860 - val_accuracy: 0.7500 - val_mae: 0.2720\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7000 - accuracy: 0.7492 - mae: 0.2663 - val_loss: 0.6852 - val_accuracy: 0.7250 - val_mae: 0.2714\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6912 - accuracy: 0.7524 - mae: 0.2686 - val_loss: 0.6841 - val_accuracy: 0.7500 - val_mae: 0.2712\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7161 - accuracy: 0.7492 - mae: 0.2672 - val_loss: 0.6837 - val_accuracy: 0.7500 - val_mae: 0.2707\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7229 - accuracy: 0.7333 - mae: 0.2729 - val_loss: 0.6844 - val_accuracy: 0.7500 - val_mae: 0.2717\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7278 - accuracy: 0.7238 - mae: 0.2740 - val_loss: 0.6829 - val_accuracy: 0.7500 - val_mae: 0.2705\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6966 - accuracy: 0.7651 - mae: 0.2626 - val_loss: 0.6821 - val_accuracy: 0.7500 - val_mae: 0.2701\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7180 - accuracy: 0.7587 - mae: 0.2721 - val_loss: 0.6827 - val_accuracy: 0.7500 - val_mae: 0.2699\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7232 - accuracy: 0.7333 - mae: 0.2702 - val_loss: 0.6837 - val_accuracy: 0.7750 - val_mae: 0.2711\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6967 - accuracy: 0.7619 - mae: 0.2660 - val_loss: 0.6828 - val_accuracy: 0.7750 - val_mae: 0.2706\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6997 - accuracy: 0.7556 - mae: 0.2672 - val_loss: 0.6823 - val_accuracy: 0.7750 - val_mae: 0.2704\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7197 - accuracy: 0.7524 - mae: 0.2688 - val_loss: 0.6819 - val_accuracy: 0.7750 - val_mae: 0.2700\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7203 - accuracy: 0.7206 - mae: 0.2722 - val_loss: 0.6833 - val_accuracy: 0.7750 - val_mae: 0.2713\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7047 - accuracy: 0.7556 - mae: 0.2622 - val_loss: 0.6832 - val_accuracy: 0.7750 - val_mae: 0.2716\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7015 - accuracy: 0.7492 - mae: 0.2669 - val_loss: 0.6816 - val_accuracy: 0.7750 - val_mae: 0.2706\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7079 - accuracy: 0.7365 - mae: 0.2685 - val_loss: 0.6809 - val_accuracy: 0.7750 - val_mae: 0.2702\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7210 - accuracy: 0.7587 - mae: 0.2687 - val_loss: 0.6799 - val_accuracy: 0.7750 - val_mae: 0.2697\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7151 - accuracy: 0.7556 - mae: 0.2688 - val_loss: 0.6796 - val_accuracy: 0.7750 - val_mae: 0.2699\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7300 - accuracy: 0.7302 - mae: 0.2716 - val_loss: 0.6799 - val_accuracy: 0.7750 - val_mae: 0.2700\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7247 - accuracy: 0.7238 - mae: 0.2728 - val_loss: 0.6802 - val_accuracy: 0.7750 - val_mae: 0.2704\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6959 - accuracy: 0.7333 - mae: 0.2641 - val_loss: 0.6802 - val_accuracy: 0.7750 - val_mae: 0.2706\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7000 - accuracy: 0.7492 - mae: 0.2629 - val_loss: 0.6782 - val_accuracy: 0.7750 - val_mae: 0.2692\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7102 - accuracy: 0.7429 - mae: 0.2694 - val_loss: 0.6781 - val_accuracy: 0.7750 - val_mae: 0.2694\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7079 - accuracy: 0.7143 - mae: 0.2705 - val_loss: 0.6767 - val_accuracy: 0.7750 - val_mae: 0.2688\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6936 - accuracy: 0.7651 - mae: 0.2628 - val_loss: 0.6750 - val_accuracy: 0.7750 - val_mae: 0.2680\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6945 - accuracy: 0.7556 - mae: 0.2641 - val_loss: 0.6743 - val_accuracy: 0.7750 - val_mae: 0.2676\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6873 - accuracy: 0.7683 - mae: 0.2622 - val_loss: 0.6735 - val_accuracy: 0.7750 - val_mae: 0.2670\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7129 - accuracy: 0.7460 - mae: 0.2663 - val_loss: 0.6729 - val_accuracy: 0.7750 - val_mae: 0.2670\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6823 - accuracy: 0.7460 - mae: 0.2608 - val_loss: 0.6726 - val_accuracy: 0.7750 - val_mae: 0.2668\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6921 - accuracy: 0.7460 - mae: 0.2600 - val_loss: 0.6734 - val_accuracy: 0.7750 - val_mae: 0.2677\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6976 - accuracy: 0.7556 - mae: 0.2647 - val_loss: 0.6722 - val_accuracy: 0.7750 - val_mae: 0.2673\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7059 - accuracy: 0.7460 - mae: 0.2687 - val_loss: 0.6714 - val_accuracy: 0.7750 - val_mae: 0.2668\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7004 - accuracy: 0.7333 - mae: 0.2679 - val_loss: 0.6714 - val_accuracy: 0.7750 - val_mae: 0.2670\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6895 - accuracy: 0.7651 - mae: 0.2633 - val_loss: 0.6715 - val_accuracy: 0.7750 - val_mae: 0.2672\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6959 - accuracy: 0.7460 - mae: 0.2639 - val_loss: 0.6711 - val_accuracy: 0.7750 - val_mae: 0.2666\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6966 - accuracy: 0.7460 - mae: 0.2616 - val_loss: 0.6720 - val_accuracy: 0.7750 - val_mae: 0.2672\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6899 - accuracy: 0.7587 - mae: 0.2601 - val_loss: 0.6718 - val_accuracy: 0.7750 - val_mae: 0.2670\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6990 - accuracy: 0.7556 - mae: 0.2642 - val_loss: 0.6720 - val_accuracy: 0.7750 - val_mae: 0.2672\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6935 - accuracy: 0.7556 - mae: 0.2613 - val_loss: 0.6714 - val_accuracy: 0.7750 - val_mae: 0.2667\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6799 - accuracy: 0.7524 - mae: 0.2577 - val_loss: 0.6714 - val_accuracy: 0.7750 - val_mae: 0.2668\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6682 - accuracy: 0.7397 - mae: 0.2579 - val_loss: 0.6719 - val_accuracy: 0.7750 - val_mae: 0.2674\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6833 - accuracy: 0.7619 - mae: 0.2623 - val_loss: 0.6710 - val_accuracy: 0.7750 - val_mae: 0.2670\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7034 - accuracy: 0.7556 - mae: 0.2616 - val_loss: 0.6709 - val_accuracy: 0.7750 - val_mae: 0.2667\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6705 - accuracy: 0.7524 - mae: 0.2594 - val_loss: 0.6698 - val_accuracy: 0.8000 - val_mae: 0.2656\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6952 - accuracy: 0.7429 - mae: 0.2633 - val_loss: 0.6703 - val_accuracy: 0.7750 - val_mae: 0.2663\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6714 - accuracy: 0.7556 - mae: 0.2576 - val_loss: 0.6697 - val_accuracy: 0.7750 - val_mae: 0.2666\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6880 - accuracy: 0.7492 - mae: 0.2632 - val_loss: 0.6682 - val_accuracy: 0.7750 - val_mae: 0.2657\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6914 - accuracy: 0.7587 - mae: 0.2629 - val_loss: 0.6692 - val_accuracy: 0.7750 - val_mae: 0.2667\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6748 - accuracy: 0.7492 - mae: 0.2561 - val_loss: 0.6699 - val_accuracy: 0.7750 - val_mae: 0.2670\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6532 - accuracy: 0.7460 - mae: 0.2539 - val_loss: 0.6694 - val_accuracy: 0.7750 - val_mae: 0.2665\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6778 - accuracy: 0.7524 - mae: 0.2563 - val_loss: 0.6673 - val_accuracy: 0.7750 - val_mae: 0.2647\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6837 - accuracy: 0.7556 - mae: 0.2587 - val_loss: 0.6677 - val_accuracy: 0.7750 - val_mae: 0.2652\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6873 - accuracy: 0.7619 - mae: 0.2631 - val_loss: 0.6656 - val_accuracy: 0.8000 - val_mae: 0.2638\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6749 - accuracy: 0.7651 - mae: 0.2561 - val_loss: 0.6658 - val_accuracy: 0.7750 - val_mae: 0.2642\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6904 - accuracy: 0.7619 - mae: 0.2618 - val_loss: 0.6663 - val_accuracy: 0.7750 - val_mae: 0.2643\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6775 - accuracy: 0.7683 - mae: 0.2570 - val_loss: 0.6660 - val_accuracy: 0.7750 - val_mae: 0.2643\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6819 - accuracy: 0.7302 - mae: 0.2612 - val_loss: 0.6659 - val_accuracy: 0.7750 - val_mae: 0.2642\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6516 - accuracy: 0.7810 - mae: 0.2491 - val_loss: 0.6669 - val_accuracy: 0.7750 - val_mae: 0.2652\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6958 - accuracy: 0.7460 - mae: 0.2645 - val_loss: 0.6680 - val_accuracy: 0.7750 - val_mae: 0.2656\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6561 - accuracy: 0.7778 - mae: 0.2537 - val_loss: 0.6660 - val_accuracy: 0.7750 - val_mae: 0.2644\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6731 - accuracy: 0.7556 - mae: 0.2575 - val_loss: 0.6657 - val_accuracy: 0.7750 - val_mae: 0.2645\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6535 - accuracy: 0.7873 - mae: 0.2529 - val_loss: 0.6650 - val_accuracy: 0.7750 - val_mae: 0.2641\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6845 - accuracy: 0.7524 - mae: 0.2580 - val_loss: 0.6639 - val_accuracy: 0.7750 - val_mae: 0.2635\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6679 - accuracy: 0.7651 - mae: 0.2551 - val_loss: 0.6657 - val_accuracy: 0.7750 - val_mae: 0.2647\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6784 - accuracy: 0.7619 - mae: 0.2612 - val_loss: 0.6645 - val_accuracy: 0.7750 - val_mae: 0.2637\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6566 - accuracy: 0.7778 - mae: 0.2506 - val_loss: 0.6623 - val_accuracy: 0.7750 - val_mae: 0.2624\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6454 - accuracy: 0.7810 - mae: 0.2493 - val_loss: 0.6623 - val_accuracy: 0.7750 - val_mae: 0.2623\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6694 - accuracy: 0.7746 - mae: 0.2535 - val_loss: 0.6624 - val_accuracy: 0.7750 - val_mae: 0.2622\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6767 - accuracy: 0.7429 - mae: 0.2562 - val_loss: 0.6631 - val_accuracy: 0.7750 - val_mae: 0.2631\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6588 - accuracy: 0.7587 - mae: 0.2527 - val_loss: 0.6631 - val_accuracy: 0.7750 - val_mae: 0.2630\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6825 - accuracy: 0.7651 - mae: 0.2586 - val_loss: 0.6636 - val_accuracy: 0.7750 - val_mae: 0.2633\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6736 - accuracy: 0.7651 - mae: 0.2535 - val_loss: 0.6626 - val_accuracy: 0.7750 - val_mae: 0.2626\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6735 - accuracy: 0.7587 - mae: 0.2529 - val_loss: 0.6638 - val_accuracy: 0.7750 - val_mae: 0.2634\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6363 - accuracy: 0.7746 - mae: 0.2463 - val_loss: 0.6627 - val_accuracy: 0.7750 - val_mae: 0.2630\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6710 - accuracy: 0.7492 - mae: 0.2550 - val_loss: 0.6612 - val_accuracy: 0.7750 - val_mae: 0.2621\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6607 - accuracy: 0.7714 - mae: 0.2529 - val_loss: 0.6607 - val_accuracy: 0.7750 - val_mae: 0.2623\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6613 - accuracy: 0.7619 - mae: 0.2515 - val_loss: 0.6600 - val_accuracy: 0.7750 - val_mae: 0.2618\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6644 - accuracy: 0.7619 - mae: 0.2536 - val_loss: 0.6594 - val_accuracy: 0.7750 - val_mae: 0.2611\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6616 - accuracy: 0.7651 - mae: 0.2528 - val_loss: 0.6602 - val_accuracy: 0.7750 - val_mae: 0.2619\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6647 - accuracy: 0.7683 - mae: 0.2538 - val_loss: 0.6623 - val_accuracy: 0.7750 - val_mae: 0.2635\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6561 - accuracy: 0.7841 - mae: 0.2542 - val_loss: 0.6597 - val_accuracy: 0.7750 - val_mae: 0.2618\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6442 - accuracy: 0.7778 - mae: 0.2500 - val_loss: 0.6598 - val_accuracy: 0.7750 - val_mae: 0.2617\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6652 - accuracy: 0.7746 - mae: 0.2524 - val_loss: 0.6594 - val_accuracy: 0.7750 - val_mae: 0.2616\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6322 - accuracy: 0.7841 - mae: 0.2465 - val_loss: 0.6577 - val_accuracy: 0.7750 - val_mae: 0.2605\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6701 - accuracy: 0.7651 - mae: 0.2526 - val_loss: 0.6572 - val_accuracy: 0.7750 - val_mae: 0.2599\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6800 - accuracy: 0.7651 - mae: 0.2545 - val_loss: 0.6577 - val_accuracy: 0.7750 - val_mae: 0.2602\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6626 - accuracy: 0.7619 - mae: 0.2515 - val_loss: 0.6584 - val_accuracy: 0.7750 - val_mae: 0.2607\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6544 - accuracy: 0.7905 - mae: 0.2513 - val_loss: 0.6610 - val_accuracy: 0.7750 - val_mae: 0.2624\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6555 - accuracy: 0.7683 - mae: 0.2521 - val_loss: 0.6588 - val_accuracy: 0.7750 - val_mae: 0.2606\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6433 - accuracy: 0.7714 - mae: 0.2480 - val_loss: 0.6585 - val_accuracy: 0.7750 - val_mae: 0.2605\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6872 - accuracy: 0.7556 - mae: 0.2574 - val_loss: 0.6587 - val_accuracy: 0.7750 - val_mae: 0.2605\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6556 - accuracy: 0.7556 - mae: 0.2504 - val_loss: 0.6574 - val_accuracy: 0.7750 - val_mae: 0.2596\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6532 - accuracy: 0.7810 - mae: 0.2504 - val_loss: 0.6563 - val_accuracy: 0.7750 - val_mae: 0.2586\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6590 - accuracy: 0.7714 - mae: 0.2503 - val_loss: 0.6566 - val_accuracy: 0.7750 - val_mae: 0.2591\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6754 - accuracy: 0.7587 - mae: 0.2547 - val_loss: 0.6584 - val_accuracy: 0.7750 - val_mae: 0.2607\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6616 - accuracy: 0.7619 - mae: 0.2511 - val_loss: 0.6566 - val_accuracy: 0.7750 - val_mae: 0.2593\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6487 - accuracy: 0.7746 - mae: 0.2499 - val_loss: 0.6562 - val_accuracy: 0.7750 - val_mae: 0.2587\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6464 - accuracy: 0.7651 - mae: 0.2481 - val_loss: 0.6561 - val_accuracy: 0.7750 - val_mae: 0.2589\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6565 - accuracy: 0.7778 - mae: 0.2511 - val_loss: 0.6555 - val_accuracy: 0.7750 - val_mae: 0.2584\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6763 - accuracy: 0.7683 - mae: 0.2527 - val_loss: 0.6572 - val_accuracy: 0.7750 - val_mae: 0.2598\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6448 - accuracy: 0.7746 - mae: 0.2445 - val_loss: 0.6565 - val_accuracy: 0.7750 - val_mae: 0.2593\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6456 - accuracy: 0.7778 - mae: 0.2493 - val_loss: 0.6562 - val_accuracy: 0.7750 - val_mae: 0.2591\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6471 - accuracy: 0.7810 - mae: 0.2457 - val_loss: 0.6547 - val_accuracy: 0.7750 - val_mae: 0.2585\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6426 - accuracy: 0.7905 - mae: 0.2434 - val_loss: 0.6541 - val_accuracy: 0.7750 - val_mae: 0.2583\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6470 - accuracy: 0.7746 - mae: 0.2488 - val_loss: 0.6549 - val_accuracy: 0.7750 - val_mae: 0.2589\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6358 - accuracy: 0.7714 - mae: 0.2498 - val_loss: 0.6540 - val_accuracy: 0.7750 - val_mae: 0.2584\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6427 - accuracy: 0.7683 - mae: 0.2456 - val_loss: 0.6521 - val_accuracy: 0.7750 - val_mae: 0.2568\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6527 - accuracy: 0.7651 - mae: 0.2479 - val_loss: 0.6518 - val_accuracy: 0.7750 - val_mae: 0.2569\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6461 - accuracy: 0.7683 - mae: 0.2452 - val_loss: 0.6512 - val_accuracy: 0.7750 - val_mae: 0.2565\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6537 - accuracy: 0.7524 - mae: 0.2458 - val_loss: 0.6520 - val_accuracy: 0.7750 - val_mae: 0.2574\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6412 - accuracy: 0.7873 - mae: 0.2440 - val_loss: 0.6529 - val_accuracy: 0.7750 - val_mae: 0.2581\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6254 - accuracy: 0.7746 - mae: 0.2429 - val_loss: 0.6518 - val_accuracy: 0.7750 - val_mae: 0.2577\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6615 - accuracy: 0.7651 - mae: 0.2496 - val_loss: 0.6508 - val_accuracy: 0.7750 - val_mae: 0.2570\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6559 - accuracy: 0.7619 - mae: 0.2487 - val_loss: 0.6513 - val_accuracy: 0.7750 - val_mae: 0.2580\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6392 - accuracy: 0.7968 - mae: 0.2456 - val_loss: 0.6492 - val_accuracy: 0.7750 - val_mae: 0.2565\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6408 - accuracy: 0.7905 - mae: 0.2451 - val_loss: 0.6480 - val_accuracy: 0.7750 - val_mae: 0.2557\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6522 - accuracy: 0.7841 - mae: 0.2492 - val_loss: 0.6486 - val_accuracy: 0.7750 - val_mae: 0.2563\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6431 - accuracy: 0.7873 - mae: 0.2450 - val_loss: 0.6474 - val_accuracy: 0.7750 - val_mae: 0.2552\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6583 - accuracy: 0.7492 - mae: 0.2461 - val_loss: 0.6461 - val_accuracy: 0.7750 - val_mae: 0.2544\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6347 - accuracy: 0.7905 - mae: 0.2437 - val_loss: 0.6477 - val_accuracy: 0.7750 - val_mae: 0.2560\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6367 - accuracy: 0.7683 - mae: 0.2440 - val_loss: 0.6470 - val_accuracy: 0.7750 - val_mae: 0.2551\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6581 - accuracy: 0.7841 - mae: 0.2503 - val_loss: 0.6482 - val_accuracy: 0.7750 - val_mae: 0.2560\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6361 - accuracy: 0.7746 - mae: 0.2463 - val_loss: 0.6484 - val_accuracy: 0.7750 - val_mae: 0.2560\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6302 - accuracy: 0.8000 - mae: 0.2420 - val_loss: 0.6468 - val_accuracy: 0.7750 - val_mae: 0.2550\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6527 - accuracy: 0.7492 - mae: 0.2502 - val_loss: 0.6471 - val_accuracy: 0.7750 - val_mae: 0.2557\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6594 - accuracy: 0.7651 - mae: 0.2510 - val_loss: 0.6484 - val_accuracy: 0.7750 - val_mae: 0.2565\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6246 - accuracy: 0.8095 - mae: 0.2411 - val_loss: 0.6467 - val_accuracy: 0.7750 - val_mae: 0.2552\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6369 - accuracy: 0.7619 - mae: 0.2444 - val_loss: 0.6458 - val_accuracy: 0.7750 - val_mae: 0.2545\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6398 - accuracy: 0.7556 - mae: 0.2454 - val_loss: 0.6472 - val_accuracy: 0.7750 - val_mae: 0.2556\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6412 - accuracy: 0.7810 - mae: 0.2423 - val_loss: 0.6472 - val_accuracy: 0.7750 - val_mae: 0.2557\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6285 - accuracy: 0.7683 - mae: 0.2425 - val_loss: 0.6469 - val_accuracy: 0.7750 - val_mae: 0.2552\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6282 - accuracy: 0.7810 - mae: 0.2410 - val_loss: 0.6470 - val_accuracy: 0.7750 - val_mae: 0.2555\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6336 - accuracy: 0.7619 - mae: 0.2437 - val_loss: 0.6464 - val_accuracy: 0.7750 - val_mae: 0.2553\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6415 - accuracy: 0.7778 - mae: 0.2465 - val_loss: 0.6447 - val_accuracy: 0.7750 - val_mae: 0.2542\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6206 - accuracy: 0.7841 - mae: 0.2401 - val_loss: 0.6451 - val_accuracy: 0.7750 - val_mae: 0.2544\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6180 - accuracy: 0.7714 - mae: 0.2395 - val_loss: 0.6453 - val_accuracy: 0.7500 - val_mae: 0.2541\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6012 - accuracy: 0.8032 - mae: 0.2363 - val_loss: 0.6454 - val_accuracy: 0.7500 - val_mae: 0.2542\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6379 - accuracy: 0.7556 - mae: 0.2474 - val_loss: 0.6454 - val_accuracy: 0.7750 - val_mae: 0.2547\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6071 - accuracy: 0.7841 - mae: 0.2387 - val_loss: 0.6442 - val_accuracy: 0.7750 - val_mae: 0.2539\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6163 - accuracy: 0.7905 - mae: 0.2374 - val_loss: 0.6448 - val_accuracy: 0.7500 - val_mae: 0.2539\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6192 - accuracy: 0.7746 - mae: 0.2358 - val_loss: 0.6450 - val_accuracy: 0.7750 - val_mae: 0.2544\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6231 - accuracy: 0.7714 - mae: 0.2413 - val_loss: 0.6448 - val_accuracy: 0.7750 - val_mae: 0.2540\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6182 - accuracy: 0.7937 - mae: 0.2401 - val_loss: 0.6440 - val_accuracy: 0.7750 - val_mae: 0.2535\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6250 - accuracy: 0.7746 - mae: 0.2378 - val_loss: 0.6449 - val_accuracy: 0.7750 - val_mae: 0.2543\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6206 - accuracy: 0.7873 - mae: 0.2379 - val_loss: 0.6432 - val_accuracy: 0.7750 - val_mae: 0.2533\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5958 - accuracy: 0.7968 - mae: 0.2324 - val_loss: 0.6430 - val_accuracy: 0.7750 - val_mae: 0.2534\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6181 - accuracy: 0.7810 - mae: 0.2390 - val_loss: 0.6429 - val_accuracy: 0.7500 - val_mae: 0.2530\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6319 - accuracy: 0.7651 - mae: 0.2386 - val_loss: 0.6437 - val_accuracy: 0.7750 - val_mae: 0.2536\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6111 - accuracy: 0.8000 - mae: 0.2366 - val_loss: 0.6441 - val_accuracy: 0.7750 - val_mae: 0.2541\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6149 - accuracy: 0.7778 - mae: 0.2379 - val_loss: 0.6430 - val_accuracy: 0.7500 - val_mae: 0.2532\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6366 - accuracy: 0.7778 - mae: 0.2423 - val_loss: 0.6414 - val_accuracy: 0.7500 - val_mae: 0.2522\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6511 - accuracy: 0.7683 - mae: 0.2435 - val_loss: 0.6418 - val_accuracy: 0.7500 - val_mae: 0.2526\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6491 - accuracy: 0.7587 - mae: 0.2464 - val_loss: 0.6431 - val_accuracy: 0.7750 - val_mae: 0.2538\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6248 - accuracy: 0.7651 - mae: 0.2418 - val_loss: 0.6441 - val_accuracy: 0.7750 - val_mae: 0.2546\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6036 - accuracy: 0.7937 - mae: 0.2364 - val_loss: 0.6434 - val_accuracy: 0.7750 - val_mae: 0.2541\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6133 - accuracy: 0.7937 - mae: 0.2374 - val_loss: 0.6419 - val_accuracy: 0.7500 - val_mae: 0.2529\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6160 - accuracy: 0.7873 - mae: 0.2407 - val_loss: 0.6408 - val_accuracy: 0.7500 - val_mae: 0.2519\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6282 - accuracy: 0.7683 - mae: 0.2400 - val_loss: 0.6419 - val_accuracy: 0.7500 - val_mae: 0.2524\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6070 - accuracy: 0.7778 - mae: 0.2335 - val_loss: 0.6410 - val_accuracy: 0.7500 - val_mae: 0.2521\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5837 - accuracy: 0.7778 - mae: 0.2307 - val_loss: 0.6402 - val_accuracy: 0.7750 - val_mae: 0.2521\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6286 - accuracy: 0.7937 - mae: 0.2406 - val_loss: 0.6398 - val_accuracy: 0.7750 - val_mae: 0.2522\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6072 - accuracy: 0.7937 - mae: 0.2326 - val_loss: 0.6382 - val_accuracy: 0.7750 - val_mae: 0.2514\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6178 - accuracy: 0.7905 - mae: 0.2311 - val_loss: 0.6389 - val_accuracy: 0.7750 - val_mae: 0.2518\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6395 - accuracy: 0.7841 - mae: 0.2415 - val_loss: 0.6375 - val_accuracy: 0.7750 - val_mae: 0.2509\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6063 - accuracy: 0.7841 - mae: 0.2324 - val_loss: 0.6370 - val_accuracy: 0.7750 - val_mae: 0.2508\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5957 - accuracy: 0.7968 - mae: 0.2322 - val_loss: 0.6379 - val_accuracy: 0.7750 - val_mae: 0.2514\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6159 - accuracy: 0.7746 - mae: 0.2363 - val_loss: 0.6369 - val_accuracy: 0.7750 - val_mae: 0.2508\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6234 - accuracy: 0.7778 - mae: 0.2394 - val_loss: 0.6347 - val_accuracy: 0.7500 - val_mae: 0.2494\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6313 - accuracy: 0.7810 - mae: 0.2349 - val_loss: 0.6358 - val_accuracy: 0.7500 - val_mae: 0.2501\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6088 - accuracy: 0.8000 - mae: 0.2318 - val_loss: 0.6356 - val_accuracy: 0.7500 - val_mae: 0.2502\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6224 - accuracy: 0.7683 - mae: 0.2355 - val_loss: 0.6363 - val_accuracy: 0.7500 - val_mae: 0.2507\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6221 - accuracy: 0.7873 - mae: 0.2366 - val_loss: 0.6354 - val_accuracy: 0.7500 - val_mae: 0.2500\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6034 - accuracy: 0.8000 - mae: 0.2349 - val_loss: 0.6352 - val_accuracy: 0.7500 - val_mae: 0.2503\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6333 - accuracy: 0.7968 - mae: 0.2402 - val_loss: 0.6345 - val_accuracy: 0.7500 - val_mae: 0.2498\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5952 - accuracy: 0.7968 - mae: 0.2324 - val_loss: 0.6335 - val_accuracy: 0.7500 - val_mae: 0.2485\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6297 - accuracy: 0.7810 - mae: 0.2349 - val_loss: 0.6360 - val_accuracy: 0.7750 - val_mae: 0.2506\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6215 - accuracy: 0.7683 - mae: 0.2397 - val_loss: 0.6369 - val_accuracy: 0.7750 - val_mae: 0.2513\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6318 - accuracy: 0.7746 - mae: 0.2395 - val_loss: 0.6362 - val_accuracy: 0.7500 - val_mae: 0.2507\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6143 - accuracy: 0.7778 - mae: 0.2328 - val_loss: 0.6375 - val_accuracy: 0.7500 - val_mae: 0.2515\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6055 - accuracy: 0.7651 - mae: 0.2347 - val_loss: 0.6353 - val_accuracy: 0.7500 - val_mae: 0.2501\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6239 - accuracy: 0.7841 - mae: 0.2359 - val_loss: 0.6353 - val_accuracy: 0.7500 - val_mae: 0.2502\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6177 - accuracy: 0.7778 - mae: 0.2364 - val_loss: 0.6346 - val_accuracy: 0.7500 - val_mae: 0.2501\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6078 - accuracy: 0.8032 - mae: 0.2334 - val_loss: 0.6349 - val_accuracy: 0.7500 - val_mae: 0.2507\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6096 - accuracy: 0.7905 - mae: 0.2355 - val_loss: 0.6343 - val_accuracy: 0.7500 - val_mae: 0.2503\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6242 - accuracy: 0.7683 - mae: 0.2377 - val_loss: 0.6325 - val_accuracy: 0.7500 - val_mae: 0.2491\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6117 - accuracy: 0.7873 - mae: 0.2324 - val_loss: 0.6327 - val_accuracy: 0.7500 - val_mae: 0.2495\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6179 - accuracy: 0.7873 - mae: 0.2349 - val_loss: 0.6329 - val_accuracy: 0.7750 - val_mae: 0.2501\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5988 - accuracy: 0.7841 - mae: 0.2332 - val_loss: 0.6327 - val_accuracy: 0.7500 - val_mae: 0.2498\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6180 - accuracy: 0.7905 - mae: 0.2392 - val_loss: 0.6317 - val_accuracy: 0.7500 - val_mae: 0.2493\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6065 - accuracy: 0.8000 - mae: 0.2341 - val_loss: 0.6316 - val_accuracy: 0.7500 - val_mae: 0.2491\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6026 - accuracy: 0.7746 - mae: 0.2324 - val_loss: 0.6316 - val_accuracy: 0.7500 - val_mae: 0.2488\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6171 - accuracy: 0.7810 - mae: 0.2347 - val_loss: 0.6318 - val_accuracy: 0.7500 - val_mae: 0.2492\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6215 - accuracy: 0.7841 - mae: 0.2393 - val_loss: 0.6314 - val_accuracy: 0.7500 - val_mae: 0.2487\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6116 - accuracy: 0.7714 - mae: 0.2349 - val_loss: 0.6321 - val_accuracy: 0.7500 - val_mae: 0.2489\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6195 - accuracy: 0.7841 - mae: 0.2371 - val_loss: 0.6336 - val_accuracy: 0.7500 - val_mae: 0.2499\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6036 - accuracy: 0.8000 - mae: 0.2347 - val_loss: 0.6330 - val_accuracy: 0.7500 - val_mae: 0.2495\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6113 - accuracy: 0.7841 - mae: 0.2354 - val_loss: 0.6332 - val_accuracy: 0.7500 - val_mae: 0.2495\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6067 - accuracy: 0.7873 - mae: 0.2325 - val_loss: 0.6334 - val_accuracy: 0.7500 - val_mae: 0.2499\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6139 - accuracy: 0.7841 - mae: 0.2371 - val_loss: 0.6343 - val_accuracy: 0.7500 - val_mae: 0.2504\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6126 - accuracy: 0.7810 - mae: 0.2358 - val_loss: 0.6331 - val_accuracy: 0.7500 - val_mae: 0.2494\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5993 - accuracy: 0.7905 - mae: 0.2314 - val_loss: 0.6330 - val_accuracy: 0.7500 - val_mae: 0.2495\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6161 - accuracy: 0.7968 - mae: 0.2346 - val_loss: 0.6336 - val_accuracy: 0.7500 - val_mae: 0.2495\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6103 - accuracy: 0.7968 - mae: 0.2360 - val_loss: 0.6353 - val_accuracy: 0.7500 - val_mae: 0.2510\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6200 - accuracy: 0.7873 - mae: 0.2394 - val_loss: 0.6348 - val_accuracy: 0.7500 - val_mae: 0.2505\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6055 - accuracy: 0.7937 - mae: 0.2344 - val_loss: 0.6348 - val_accuracy: 0.7500 - val_mae: 0.2502\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6262 - accuracy: 0.7746 - mae: 0.2360 - val_loss: 0.6347 - val_accuracy: 0.7500 - val_mae: 0.2496\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6155 - accuracy: 0.7873 - mae: 0.2355 - val_loss: 0.6353 - val_accuracy: 0.7500 - val_mae: 0.2502\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6178 - accuracy: 0.7651 - mae: 0.2356 - val_loss: 0.6346 - val_accuracy: 0.7500 - val_mae: 0.2500\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6154 - accuracy: 0.7683 - mae: 0.2338 - val_loss: 0.6352 - val_accuracy: 0.7500 - val_mae: 0.2506\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6014 - accuracy: 0.8063 - mae: 0.2323 - val_loss: 0.6345 - val_accuracy: 0.7500 - val_mae: 0.2504\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6041 - accuracy: 0.7968 - mae: 0.2314 - val_loss: 0.6344 - val_accuracy: 0.7500 - val_mae: 0.2506\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6054 - accuracy: 0.7905 - mae: 0.2344 - val_loss: 0.6347 - val_accuracy: 0.7500 - val_mae: 0.2507\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6046 - accuracy: 0.7810 - mae: 0.2348 - val_loss: 0.6343 - val_accuracy: 0.7500 - val_mae: 0.2504\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6122 - accuracy: 0.7968 - mae: 0.2334 - val_loss: 0.6334 - val_accuracy: 0.7500 - val_mae: 0.2498\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5948 - accuracy: 0.7937 - mae: 0.2302 - val_loss: 0.6326 - val_accuracy: 0.7500 - val_mae: 0.2495\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6116 - accuracy: 0.7778 - mae: 0.2343 - val_loss: 0.6325 - val_accuracy: 0.7500 - val_mae: 0.2497\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6059 - accuracy: 0.7937 - mae: 0.2361 - val_loss: 0.6332 - val_accuracy: 0.7500 - val_mae: 0.2501\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6018 - accuracy: 0.7810 - mae: 0.2315 - val_loss: 0.6334 - val_accuracy: 0.7500 - val_mae: 0.2499\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5858 - accuracy: 0.8032 - mae: 0.2299 - val_loss: 0.6324 - val_accuracy: 0.7500 - val_mae: 0.2495\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6060 - accuracy: 0.7968 - mae: 0.2337 - val_loss: 0.6304 - val_accuracy: 0.7500 - val_mae: 0.2483\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6052 - accuracy: 0.7937 - mae: 0.2321 - val_loss: 0.6296 - val_accuracy: 0.7500 - val_mae: 0.2478\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6079 - accuracy: 0.8000 - mae: 0.2332 - val_loss: 0.6299 - val_accuracy: 0.7500 - val_mae: 0.2483\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5768 - accuracy: 0.8063 - mae: 0.2244 - val_loss: 0.6288 - val_accuracy: 0.7500 - val_mae: 0.2478\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5876 - accuracy: 0.7841 - mae: 0.2307 - val_loss: 0.6299 - val_accuracy: 0.7500 - val_mae: 0.2485\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5878 - accuracy: 0.8190 - mae: 0.2288 - val_loss: 0.6306 - val_accuracy: 0.7500 - val_mae: 0.2492\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5741 - accuracy: 0.8159 - mae: 0.2240 - val_loss: 0.6291 - val_accuracy: 0.7500 - val_mae: 0.2478\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5997 - accuracy: 0.7905 - mae: 0.2289 - val_loss: 0.6287 - val_accuracy: 0.7500 - val_mae: 0.2475\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6088 - accuracy: 0.7873 - mae: 0.2348 - val_loss: 0.6275 - val_accuracy: 0.7500 - val_mae: 0.2466\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6105 - accuracy: 0.7746 - mae: 0.2341 - val_loss: 0.6276 - val_accuracy: 0.7500 - val_mae: 0.2466\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6038 - accuracy: 0.7873 - mae: 0.2302 - val_loss: 0.6278 - val_accuracy: 0.7750 - val_mae: 0.2469\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6133 - accuracy: 0.7841 - mae: 0.2309 - val_loss: 0.6291 - val_accuracy: 0.7500 - val_mae: 0.2483\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6085 - accuracy: 0.7746 - mae: 0.2328 - val_loss: 0.6295 - val_accuracy: 0.7500 - val_mae: 0.2484\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5828 - accuracy: 0.8127 - mae: 0.2254 - val_loss: 0.6287 - val_accuracy: 0.7500 - val_mae: 0.2484\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5823 - accuracy: 0.7810 - mae: 0.2288 - val_loss: 0.6264 - val_accuracy: 0.7500 - val_mae: 0.2470\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5856 - accuracy: 0.7968 - mae: 0.2247 - val_loss: 0.6247 - val_accuracy: 0.7750 - val_mae: 0.2460\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5861 - accuracy: 0.7968 - mae: 0.2254 - val_loss: 0.6259 - val_accuracy: 0.7500 - val_mae: 0.2472\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6008 - accuracy: 0.8032 - mae: 0.2292 - val_loss: 0.6275 - val_accuracy: 0.7500 - val_mae: 0.2479\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5598 - accuracy: 0.8254 - mae: 0.2196 - val_loss: 0.6247 - val_accuracy: 0.7500 - val_mae: 0.2460\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5784 - accuracy: 0.8000 - mae: 0.2223 - val_loss: 0.6244 - val_accuracy: 0.7500 - val_mae: 0.2459\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5870 - accuracy: 0.7810 - mae: 0.2280 - val_loss: 0.6233 - val_accuracy: 0.7500 - val_mae: 0.2456\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5934 - accuracy: 0.7810 - mae: 0.2308 - val_loss: 0.6255 - val_accuracy: 0.7500 - val_mae: 0.2472\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5937 - accuracy: 0.7905 - mae: 0.2302 - val_loss: 0.6265 - val_accuracy: 0.7500 - val_mae: 0.2474\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5931 - accuracy: 0.7873 - mae: 0.2307 - val_loss: 0.6246 - val_accuracy: 0.7500 - val_mae: 0.2461\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5766 - accuracy: 0.7810 - mae: 0.2257 - val_loss: 0.6236 - val_accuracy: 0.7500 - val_mae: 0.2453\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5877 - accuracy: 0.7968 - mae: 0.2262 - val_loss: 0.6244 - val_accuracy: 0.7500 - val_mae: 0.2456\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5738 - accuracy: 0.8159 - mae: 0.2237 - val_loss: 0.6248 - val_accuracy: 0.7500 - val_mae: 0.2459\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6081 - accuracy: 0.7746 - mae: 0.2302 - val_loss: 0.6248 - val_accuracy: 0.7500 - val_mae: 0.2461\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5819 - accuracy: 0.8032 - mae: 0.2240 - val_loss: 0.6236 - val_accuracy: 0.7500 - val_mae: 0.2450\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5911 - accuracy: 0.8127 - mae: 0.2312 - val_loss: 0.6244 - val_accuracy: 0.7500 - val_mae: 0.2450\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6049 - accuracy: 0.7905 - mae: 0.2282 - val_loss: 0.6246 - val_accuracy: 0.7500 - val_mae: 0.2453\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6037 - accuracy: 0.7841 - mae: 0.2310 - val_loss: 0.6250 - val_accuracy: 0.7500 - val_mae: 0.2458\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5807 - accuracy: 0.7905 - mae: 0.2239 - val_loss: 0.6259 - val_accuracy: 0.7500 - val_mae: 0.2468\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7746 - mae: 0.2261 - val_loss: 0.6234 - val_accuracy: 0.7500 - val_mae: 0.2450\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5814 - accuracy: 0.7841 - mae: 0.2253 - val_loss: 0.6227 - val_accuracy: 0.7500 - val_mae: 0.2445\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5772 - accuracy: 0.8000 - mae: 0.2235 - val_loss: 0.6222 - val_accuracy: 0.7500 - val_mae: 0.2440\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5815 - accuracy: 0.8032 - mae: 0.2224 - val_loss: 0.6213 - val_accuracy: 0.7750 - val_mae: 0.2434\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6169 - accuracy: 0.7905 - mae: 0.2316 - val_loss: 0.6231 - val_accuracy: 0.7500 - val_mae: 0.2448\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5944 - accuracy: 0.8000 - mae: 0.2279 - val_loss: 0.6253 - val_accuracy: 0.7500 - val_mae: 0.2467\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5822 - accuracy: 0.8032 - mae: 0.2251 - val_loss: 0.6263 - val_accuracy: 0.7500 - val_mae: 0.2473\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5910 - accuracy: 0.7937 - mae: 0.2274 - val_loss: 0.6248 - val_accuracy: 0.7500 - val_mae: 0.2457\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5822 - accuracy: 0.7937 - mae: 0.2247 - val_loss: 0.6232 - val_accuracy: 0.7750 - val_mae: 0.2447\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5933 - accuracy: 0.8095 - mae: 0.2260 - val_loss: 0.6231 - val_accuracy: 0.7500 - val_mae: 0.2454\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5741 - accuracy: 0.7810 - mae: 0.2259 - val_loss: 0.6222 - val_accuracy: 0.7500 - val_mae: 0.2451\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5927 - accuracy: 0.7746 - mae: 0.2277 - val_loss: 0.6220 - val_accuracy: 0.7500 - val_mae: 0.2451\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5685 - accuracy: 0.8349 - mae: 0.2233 - val_loss: 0.6209 - val_accuracy: 0.7500 - val_mae: 0.2445\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5794 - accuracy: 0.7968 - mae: 0.2230 - val_loss: 0.6216 - val_accuracy: 0.7500 - val_mae: 0.2448\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5953 - accuracy: 0.7841 - mae: 0.2285 - val_loss: 0.6213 - val_accuracy: 0.7500 - val_mae: 0.2444\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6038 - accuracy: 0.7841 - mae: 0.2285 - val_loss: 0.6218 - val_accuracy: 0.7500 - val_mae: 0.2447\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5725 - accuracy: 0.8159 - mae: 0.2190 - val_loss: 0.6233 - val_accuracy: 0.7500 - val_mae: 0.2454\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5851 - accuracy: 0.7873 - mae: 0.2238 - val_loss: 0.6237 - val_accuracy: 0.7500 - val_mae: 0.2456\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5799 - accuracy: 0.7937 - mae: 0.2256 - val_loss: 0.6230 - val_accuracy: 0.7500 - val_mae: 0.2453\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5913 - accuracy: 0.7873 - mae: 0.2273 - val_loss: 0.6213 - val_accuracy: 0.7500 - val_mae: 0.2441\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5865 - accuracy: 0.8095 - mae: 0.2239 - val_loss: 0.6219 - val_accuracy: 0.7500 - val_mae: 0.2447\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5851 - accuracy: 0.7905 - mae: 0.2260 - val_loss: 0.6215 - val_accuracy: 0.7500 - val_mae: 0.2445\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5889 - accuracy: 0.7873 - mae: 0.2261 - val_loss: 0.6228 - val_accuracy: 0.7500 - val_mae: 0.2450\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5841 - accuracy: 0.8127 - mae: 0.2268 - val_loss: 0.6245 - val_accuracy: 0.7500 - val_mae: 0.2458\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5738 - accuracy: 0.7968 - mae: 0.2229 - val_loss: 0.6238 - val_accuracy: 0.7500 - val_mae: 0.2457\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5743 - accuracy: 0.8063 - mae: 0.2207 - val_loss: 0.6230 - val_accuracy: 0.7500 - val_mae: 0.2453\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5813 - accuracy: 0.8000 - mae: 0.2244 - val_loss: 0.6234 - val_accuracy: 0.7500 - val_mae: 0.2460\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5750 - accuracy: 0.7937 - mae: 0.2215 - val_loss: 0.6225 - val_accuracy: 0.7500 - val_mae: 0.2456\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5840 - accuracy: 0.8063 - mae: 0.2243 - val_loss: 0.6215 - val_accuracy: 0.7500 - val_mae: 0.2447\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5661 - accuracy: 0.8000 - mae: 0.2216 - val_loss: 0.6203 - val_accuracy: 0.7750 - val_mae: 0.2440\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5840 - accuracy: 0.7778 - mae: 0.2257 - val_loss: 0.6218 - val_accuracy: 0.7500 - val_mae: 0.2447\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5944 - accuracy: 0.7968 - mae: 0.2284 - val_loss: 0.6226 - val_accuracy: 0.7500 - val_mae: 0.2449\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5661 - accuracy: 0.8000 - mae: 0.2240 - val_loss: 0.6212 - val_accuracy: 0.7500 - val_mae: 0.2439\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5851 - accuracy: 0.7905 - mae: 0.2275 - val_loss: 0.6207 - val_accuracy: 0.7500 - val_mae: 0.2437\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5802 - accuracy: 0.7746 - mae: 0.2214 - val_loss: 0.6202 - val_accuracy: 0.7500 - val_mae: 0.2435\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5896 - accuracy: 0.7937 - mae: 0.2269 - val_loss: 0.6219 - val_accuracy: 0.7500 - val_mae: 0.2447\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5787 - accuracy: 0.8063 - mae: 0.2243 - val_loss: 0.6235 - val_accuracy: 0.7500 - val_mae: 0.2458\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5851 - accuracy: 0.7968 - mae: 0.2251 - val_loss: 0.6231 - val_accuracy: 0.7500 - val_mae: 0.2454\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5847 - accuracy: 0.8000 - mae: 0.2265 - val_loss: 0.6223 - val_accuracy: 0.7500 - val_mae: 0.2449\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5743 - accuracy: 0.8159 - mae: 0.2249 - val_loss: 0.6218 - val_accuracy: 0.7500 - val_mae: 0.2449\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5730 - accuracy: 0.8127 - mae: 0.2239 - val_loss: 0.6208 - val_accuracy: 0.7500 - val_mae: 0.2445\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5577 - accuracy: 0.7841 - mae: 0.2192 - val_loss: 0.6205 - val_accuracy: 0.7500 - val_mae: 0.2446\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5749 - accuracy: 0.8063 - mae: 0.2250 - val_loss: 0.6196 - val_accuracy: 0.7500 - val_mae: 0.2439\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5705 - accuracy: 0.7905 - mae: 0.2191 - val_loss: 0.6199 - val_accuracy: 0.7500 - val_mae: 0.2439\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5893 - accuracy: 0.7841 - mae: 0.2228 - val_loss: 0.6191 - val_accuracy: 0.7500 - val_mae: 0.2431\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5689 - accuracy: 0.8190 - mae: 0.2235 - val_loss: 0.6196 - val_accuracy: 0.7500 - val_mae: 0.2435\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5781 - accuracy: 0.7841 - mae: 0.2240 - val_loss: 0.6188 - val_accuracy: 0.7500 - val_mae: 0.2428\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5697 - accuracy: 0.7968 - mae: 0.2196 - val_loss: 0.6189 - val_accuracy: 0.7500 - val_mae: 0.2430\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5786 - accuracy: 0.7841 - mae: 0.2222 - val_loss: 0.6193 - val_accuracy: 0.7500 - val_mae: 0.2436\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5678 - accuracy: 0.8000 - mae: 0.2179 - val_loss: 0.6185 - val_accuracy: 0.7500 - val_mae: 0.2429\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5676 - accuracy: 0.8159 - mae: 0.2203 - val_loss: 0.6189 - val_accuracy: 0.7500 - val_mae: 0.2434\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5812 - accuracy: 0.7841 - mae: 0.2278 - val_loss: 0.6186 - val_accuracy: 0.7500 - val_mae: 0.2429\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5747 - accuracy: 0.7968 - mae: 0.2192 - val_loss: 0.6182 - val_accuracy: 0.7750 - val_mae: 0.2422\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5686 - accuracy: 0.8000 - mae: 0.2193 - val_loss: 0.6182 - val_accuracy: 0.7500 - val_mae: 0.2424\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5889 - accuracy: 0.7905 - mae: 0.2266 - val_loss: 0.6186 - val_accuracy: 0.7500 - val_mae: 0.2430\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5770 - accuracy: 0.7968 - mae: 0.2239 - val_loss: 0.6195 - val_accuracy: 0.7500 - val_mae: 0.2439\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5635 - accuracy: 0.8190 - mae: 0.2202 - val_loss: 0.6198 - val_accuracy: 0.7500 - val_mae: 0.2437\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5732 - accuracy: 0.7841 - mae: 0.2224 - val_loss: 0.6186 - val_accuracy: 0.7500 - val_mae: 0.2432\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5588 - accuracy: 0.8032 - mae: 0.2184 - val_loss: 0.6177 - val_accuracy: 0.7500 - val_mae: 0.2426\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5737 - accuracy: 0.7968 - mae: 0.2220 - val_loss: 0.6183 - val_accuracy: 0.7500 - val_mae: 0.2432\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5656 - accuracy: 0.7968 - mae: 0.2226 - val_loss: 0.6180 - val_accuracy: 0.7500 - val_mae: 0.2433\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5760 - accuracy: 0.7905 - mae: 0.2243 - val_loss: 0.6165 - val_accuracy: 0.7500 - val_mae: 0.2422\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5697 - accuracy: 0.8063 - mae: 0.2205 - val_loss: 0.6172 - val_accuracy: 0.7500 - val_mae: 0.2425\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5535 - accuracy: 0.8063 - mae: 0.2165 - val_loss: 0.6152 - val_accuracy: 0.7750 - val_mae: 0.2402\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5610 - accuracy: 0.8190 - mae: 0.2184 - val_loss: 0.6165 - val_accuracy: 0.7500 - val_mae: 0.2419\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5802 - accuracy: 0.8032 - mae: 0.2226 - val_loss: 0.6166 - val_accuracy: 0.7750 - val_mae: 0.2416\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5610 - accuracy: 0.8032 - mae: 0.2188 - val_loss: 0.6171 - val_accuracy: 0.7750 - val_mae: 0.2415\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5735 - accuracy: 0.7810 - mae: 0.2195 - val_loss: 0.6187 - val_accuracy: 0.7500 - val_mae: 0.2425\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5524 - accuracy: 0.8127 - mae: 0.2163 - val_loss: 0.6195 - val_accuracy: 0.7500 - val_mae: 0.2430\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5923 - accuracy: 0.7810 - mae: 0.2265 - val_loss: 0.6190 - val_accuracy: 0.7500 - val_mae: 0.2431\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5763 - accuracy: 0.7937 - mae: 0.2221 - val_loss: 0.6181 - val_accuracy: 0.7500 - val_mae: 0.2422\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5726 - accuracy: 0.8222 - mae: 0.2237 - val_loss: 0.6199 - val_accuracy: 0.7500 - val_mae: 0.2434\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5895 - accuracy: 0.7937 - mae: 0.2277 - val_loss: 0.6191 - val_accuracy: 0.7500 - val_mae: 0.2431\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5793 - accuracy: 0.7968 - mae: 0.2245 - val_loss: 0.6192 - val_accuracy: 0.7750 - val_mae: 0.2426\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5783 - accuracy: 0.7810 - mae: 0.2238 - val_loss: 0.6194 - val_accuracy: 0.7750 - val_mae: 0.2431\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5713 - accuracy: 0.8254 - mae: 0.2190 - val_loss: 0.6201 - val_accuracy: 0.7500 - val_mae: 0.2437\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5576 - accuracy: 0.8095 - mae: 0.2175 - val_loss: 0.6194 - val_accuracy: 0.7500 - val_mae: 0.2436\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5601 - accuracy: 0.8127 - mae: 0.2173 - val_loss: 0.6193 - val_accuracy: 0.7500 - val_mae: 0.2436\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5732 - accuracy: 0.8095 - mae: 0.2219 - val_loss: 0.6176 - val_accuracy: 0.7500 - val_mae: 0.2422\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5638 - accuracy: 0.8095 - mae: 0.2157 - val_loss: 0.6177 - val_accuracy: 0.7500 - val_mae: 0.2418\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5803 - accuracy: 0.8127 - mae: 0.2202 - val_loss: 0.6175 - val_accuracy: 0.7500 - val_mae: 0.2420\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5829 - accuracy: 0.8063 - mae: 0.2239 - val_loss: 0.6187 - val_accuracy: 0.7500 - val_mae: 0.2430\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5444 - accuracy: 0.8127 - mae: 0.2161 - val_loss: 0.6214 - val_accuracy: 0.7500 - val_mae: 0.2447\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5887 - accuracy: 0.8032 - mae: 0.2220 - val_loss: 0.6210 - val_accuracy: 0.7500 - val_mae: 0.2444\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5658 - accuracy: 0.8000 - mae: 0.2201 - val_loss: 0.6192 - val_accuracy: 0.7500 - val_mae: 0.2433\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5491 - accuracy: 0.8317 - mae: 0.2178 - val_loss: 0.6168 - val_accuracy: 0.7750 - val_mae: 0.2415\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5631 - accuracy: 0.8000 - mae: 0.2189 - val_loss: 0.6177 - val_accuracy: 0.7500 - val_mae: 0.2422\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5769 - accuracy: 0.8032 - mae: 0.2205 - val_loss: 0.6170 - val_accuracy: 0.7500 - val_mae: 0.2419\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5717 - accuracy: 0.7968 - mae: 0.2215 - val_loss: 0.6195 - val_accuracy: 0.7500 - val_mae: 0.2436\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5592 - accuracy: 0.8000 - mae: 0.2197 - val_loss: 0.6180 - val_accuracy: 0.7500 - val_mae: 0.2425\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5707 - accuracy: 0.7968 - mae: 0.2188 - val_loss: 0.6171 - val_accuracy: 0.7750 - val_mae: 0.2417\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5542 - accuracy: 0.8222 - mae: 0.2172 - val_loss: 0.6160 - val_accuracy: 0.7750 - val_mae: 0.2409\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5515 - accuracy: 0.8127 - mae: 0.2152 - val_loss: 0.6166 - val_accuracy: 0.7500 - val_mae: 0.2414\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5765 - accuracy: 0.8000 - mae: 0.2205 - val_loss: 0.6183 - val_accuracy: 0.7500 - val_mae: 0.2425\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5568 - accuracy: 0.8159 - mae: 0.2185 - val_loss: 0.6186 - val_accuracy: 0.7500 - val_mae: 0.2425\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5509 - accuracy: 0.8254 - mae: 0.2184 - val_loss: 0.6174 - val_accuracy: 0.7500 - val_mae: 0.2416\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5616 - accuracy: 0.8095 - mae: 0.2168 - val_loss: 0.6153 - val_accuracy: 0.7500 - val_mae: 0.2407\n"
     ]
    }
   ],
   "source": [
    "nn_handler.train_model(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler.class_model.save(datadir + \"TL_neatms_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 1s 6ms/step\n",
      "127/127 [==============================] - 1s 6ms/step\n",
      "126/126 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Set the threshold to 0.22\n",
    "threshold=0.22\n",
    "# Run the prediction\n",
    "nn_handler.predict_peaks(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>m/z</th>\n",
       "      <th>retention time</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>54.977012</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>153221.001212</td>\n",
       "      <td>153221.001212</td>\n",
       "      <td>High_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B1_NIST1950_2_6540</td>\n",
       "      <td>54.977012</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>121049.319269</td>\n",
       "      <td>121049.319269</td>\n",
       "      <td>High_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B1_NIST1950_3_6540</td>\n",
       "      <td>54.977012</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>121518.648674</td>\n",
       "      <td>121518.648674</td>\n",
       "      <td>High_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>55.018832</td>\n",
       "      <td>6.038233</td>\n",
       "      <td>6447.719840</td>\n",
       "      <td>6447.719840</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>B1_NIST1950_2_6540</td>\n",
       "      <td>55.018832</td>\n",
       "      <td>6.038233</td>\n",
       "      <td>9208.601970</td>\n",
       "      <td>9208.601970</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>4186</td>\n",
       "      <td>B1_NIST1950_2_6540</td>\n",
       "      <td>1613.977307</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>49999.415489</td>\n",
       "      <td>49999.415489</td>\n",
       "      <td>High_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12093</th>\n",
       "      <td>4186</td>\n",
       "      <td>B1_NIST1950_3_6540</td>\n",
       "      <td>1613.977307</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>23885.945518</td>\n",
       "      <td>23885.945518</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12094</th>\n",
       "      <td>4187</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1613.978958</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>13252.754702</td>\n",
       "      <td>13252.754702</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12095</th>\n",
       "      <td>4187</td>\n",
       "      <td>B1_NIST1950_2_6540</td>\n",
       "      <td>1613.978958</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>15256.555134</td>\n",
       "      <td>15256.555134</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12096</th>\n",
       "      <td>4187</td>\n",
       "      <td>B1_NIST1950_3_6540</td>\n",
       "      <td>1613.978958</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>22642.497262</td>\n",
       "      <td>22642.497262</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12097 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature ID              sample          m/z  retention time  \\\n",
       "0               1  B1_NIST1950_1_6540    54.977012        5.074017   \n",
       "1               1  B1_NIST1950_2_6540    54.977012        5.074017   \n",
       "2               1  B1_NIST1950_3_6540    54.977012        5.074017   \n",
       "3               2  B1_NIST1950_1_6540    55.018832        6.038233   \n",
       "4               2  B1_NIST1950_2_6540    55.018832        6.038233   \n",
       "...           ...                 ...          ...             ...   \n",
       "12092        4186  B1_NIST1950_2_6540  1613.977307       14.982067   \n",
       "12093        4186  B1_NIST1950_3_6540  1613.977307       14.982067   \n",
       "12094        4187  B1_NIST1950_1_6540  1613.978958       12.721182   \n",
       "12095        4187  B1_NIST1950_2_6540  1613.978958       12.721182   \n",
       "12096        4187  B1_NIST1950_3_6540  1613.978958       12.721182   \n",
       "\n",
       "              height           area         label  \n",
       "0      153221.001212  153221.001212  High_quality  \n",
       "1      121049.319269  121049.319269  High_quality  \n",
       "2      121518.648674  121518.648674  High_quality  \n",
       "3        6447.719840    6447.719840         Noise  \n",
       "4        9208.601970    9208.601970         Noise  \n",
       "...              ...            ...           ...  \n",
       "12092   49999.415489   49999.415489  High_quality  \n",
       "12093   23885.945518   23885.945518         Noise  \n",
       "12094   13252.754702   13252.754702         Noise  \n",
       "12095   15256.555134   15256.555134         Noise  \n",
       "12096   22642.497262   22642.497262         Noise  \n",
       "\n",
       "[12097 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create the dataframe using this function\n",
    "NeatMS_output_df = experiment.export_to_dataframe()\n",
    "# And display it\n",
    "NeatMS_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>m/z</th>\n",
       "      <th>retention time</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>54.977012</td>\n",
       "      <td>5.074017</td>\n",
       "      <td>1.532210e+05</td>\n",
       "      <td>1.532210e+05</td>\n",
       "      <td>High_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>55.018832</td>\n",
       "      <td>6.038233</td>\n",
       "      <td>6.447720e+03</td>\n",
       "      <td>6.447720e+03</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>56.995900</td>\n",
       "      <td>13.086900</td>\n",
       "      <td>6.127502e+06</td>\n",
       "      <td>6.127502e+06</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>57.034581</td>\n",
       "      <td>1.590991</td>\n",
       "      <td>3.627522e+04</td>\n",
       "      <td>3.627522e+04</td>\n",
       "      <td>High_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>57.028878</td>\n",
       "      <td>12.804283</td>\n",
       "      <td>2.734232e+03</td>\n",
       "      <td>2.734232e+03</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>4183</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1612.974722</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>1.910637e+04</td>\n",
       "      <td>1.910637e+04</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085</th>\n",
       "      <td>4184</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1612.976154</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>1.358256e+04</td>\n",
       "      <td>1.358256e+04</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>4185</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1613.978101</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>3.174946e+03</td>\n",
       "      <td>3.174946e+03</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12091</th>\n",
       "      <td>4186</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1613.977307</td>\n",
       "      <td>14.982067</td>\n",
       "      <td>2.855932e+04</td>\n",
       "      <td>2.855932e+04</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12094</th>\n",
       "      <td>4187</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>1613.978958</td>\n",
       "      <td>12.721182</td>\n",
       "      <td>1.325275e+04</td>\n",
       "      <td>1.325275e+04</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4034 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature ID              sample          m/z  retention time  \\\n",
       "0               1  B1_NIST1950_1_6540    54.977012        5.074017   \n",
       "3               2  B1_NIST1950_1_6540    55.018832        6.038233   \n",
       "6               3  B1_NIST1950_1_6540    56.995900       13.086900   \n",
       "9               4  B1_NIST1950_1_6540    57.034581        1.590991   \n",
       "12              5  B1_NIST1950_1_6540    57.028878       12.804283   \n",
       "...           ...                 ...          ...             ...   \n",
       "12082        4183  B1_NIST1950_1_6540  1612.974722        2.214650   \n",
       "12085        4184  B1_NIST1950_1_6540  1612.976154       14.982067   \n",
       "12088        4185  B1_NIST1950_1_6540  1613.978101        2.214650   \n",
       "12091        4186  B1_NIST1950_1_6540  1613.977307       14.982067   \n",
       "12094        4187  B1_NIST1950_1_6540  1613.978958       12.721182   \n",
       "\n",
       "             height          area         label  \n",
       "0      1.532210e+05  1.532210e+05  High_quality  \n",
       "3      6.447720e+03  6.447720e+03         Noise  \n",
       "6      6.127502e+06  6.127502e+06         Noise  \n",
       "9      3.627522e+04  3.627522e+04  High_quality  \n",
       "12     2.734232e+03  2.734232e+03         Noise  \n",
       "...             ...           ...           ...  \n",
       "12082  1.910637e+04  1.910637e+04         Noise  \n",
       "12085  1.358256e+04  1.358256e+04         Noise  \n",
       "12088  3.174946e+03  3.174946e+03         Noise  \n",
       "12091  2.855932e+04  2.855932e+04         Noise  \n",
       "12094  1.325275e+04  1.325275e+04         Noise  \n",
       "\n",
       "[4034 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = NeatMS_output_df[NeatMS_output_df[\"sample\"] == files[0].replace(\".mzML\",\"\")]\n",
    "filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "matchIDs = {}\n",
    "for index,row in peaks_test.iterrows():\n",
    "    for index2,row2 in filt.iterrows():\n",
    "        if row2[\"m/z\"] > row[\"mz\"] + 0.001:\n",
    "            break\n",
    "        if np.abs(row[\"rt\"] - row2[\"retention time\"]) < 0.03:\n",
    "            if np.abs(row[\"mz\"] - row2[\"m/z\"]) < 0.001:\n",
    "                matchIDs[index] = index2\n",
    "                break\n",
    "print(len(matchIDs))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature ID</th>\n",
       "      <th>sample</th>\n",
       "      <th>m/z</th>\n",
       "      <th>retention time</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>label</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10717</th>\n",
       "      <td>3719</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>638.103711</td>\n",
       "      <td>0.724168</td>\n",
       "      <td>6050.758047</td>\n",
       "      <td>6050.758047</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4403</th>\n",
       "      <td>1525</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>254.624195</td>\n",
       "      <td>0.834850</td>\n",
       "      <td>98824.035679</td>\n",
       "      <td>98824.035679</td>\n",
       "      <td>High_quality</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10846</th>\n",
       "      <td>3765</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>666.784066</td>\n",
       "      <td>13.086900</td>\n",
       "      <td>8112.694799</td>\n",
       "      <td>8112.694799</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>1750</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>275.202386</td>\n",
       "      <td>0.851467</td>\n",
       "      <td>46051.935219</td>\n",
       "      <td>46051.935219</td>\n",
       "      <td>High_quality</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>2924</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>442.265574</td>\n",
       "      <td>0.984468</td>\n",
       "      <td>6923.086015</td>\n",
       "      <td>6923.086015</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>1471</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>249.975378</td>\n",
       "      <td>9.047198</td>\n",
       "      <td>323861.620950</td>\n",
       "      <td>323861.620950</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9940</th>\n",
       "      <td>3448</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>550.455573</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>22174.686775</td>\n",
       "      <td>22174.686775</td>\n",
       "      <td>High_quality</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10735</th>\n",
       "      <td>3725</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>640.129377</td>\n",
       "      <td>0.917967</td>\n",
       "      <td>8536.802503</td>\n",
       "      <td>8536.802503</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>2320</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>340.236364</td>\n",
       "      <td>0.934592</td>\n",
       "      <td>79630.589056</td>\n",
       "      <td>79630.589056</td>\n",
       "      <td>High_quality</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>1815</td>\n",
       "      <td>B1_NIST1950_1_6540</td>\n",
       "      <td>283.064220</td>\n",
       "      <td>6.154736</td>\n",
       "      <td>2902.056490</td>\n",
       "      <td>2902.056490</td>\n",
       "      <td>Noise</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature ID              sample         m/z  retention time  \\\n",
       "10717        3719  B1_NIST1950_1_6540  638.103711        0.724168   \n",
       "4403         1525  B1_NIST1950_1_6540  254.624195        0.834850   \n",
       "10846        3765  B1_NIST1950_1_6540  666.784066       13.086900   \n",
       "5069         1750  B1_NIST1950_1_6540  275.202386        0.851467   \n",
       "8450         2924  B1_NIST1950_1_6540  442.265574        0.984468   \n",
       "...           ...                 ...         ...             ...   \n",
       "4241         1471  B1_NIST1950_1_6540  249.975378        9.047198   \n",
       "9940         3448  B1_NIST1950_1_6540  550.455573        0.784983   \n",
       "10735        3725  B1_NIST1950_1_6540  640.129377        0.917967   \n",
       "6710         2320  B1_NIST1950_1_6540  340.236364        0.934592   \n",
       "5259         1815  B1_NIST1950_1_6540  283.064220        6.154736   \n",
       "\n",
       "              height           area         label  classification  \n",
       "10717    6050.758047    6050.758047         Noise             0.0  \n",
       "4403    98824.035679   98824.035679  High_quality             1.0  \n",
       "10846    8112.694799    8112.694799         Noise             0.0  \n",
       "5069    46051.935219   46051.935219  High_quality             1.0  \n",
       "8450     6923.086015    6923.086015         Noise             0.0  \n",
       "...              ...            ...           ...             ...  \n",
       "4241   323861.620950  323861.620950         Noise             0.0  \n",
       "9940    22174.686775   22174.686775  High_quality             1.0  \n",
       "10735    8536.802503    8536.802503         Noise             0.0  \n",
       "6710    79630.589056   79630.589056  High_quality             1.0  \n",
       "5259     2902.056490    2902.056490         Noise             0.0  \n",
       "\n",
       "[147 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = list(matchIDs.keys())\n",
    "filt = filt.loc[[matchIDs[x] for x in order],:]\n",
    "classification = []\n",
    "for index,row in filt.iterrows():\n",
    "    if row[\"label\"] == \"High_quality\":\n",
    "        classification.append(1.0)\n",
    "    elif row[\"label\"] == \"Low_quality\":\n",
    "        classification.append(0.5)\n",
    "    else:\n",
    "        classification.append(0.0)\n",
    "filt[\"classification\"] = classification\n",
    "filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scores_neat_ms_TL = filt[\"classification\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "integ.load(datadir + \"active/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "y_test_scores_active_syn = integ.classifyMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "makePRCPlot(y_test_scores_active_syn[:,1],y_test[:,1],noSkill=True,label=\"active PD\")\n",
    "makePRCPlot(y_test_scores_neat_ms,y_test[:,1],noSkill=False,label=\"NeatMS\")\n",
    "makePRCPlot(y_test_scores_neat_ms_TL,y_test[:,1],noSkill=False,label=\"NeatMS_TL\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(datadir+\"PRC_TL.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "makeROCPlot(y_test_scores_active_syn[:,1],y_test[:,1],noSkill=True,label=\"active PD\")\n",
    "makeROCPlot(y_test_scores_neat_ms,y_test[:,1],noSkill=False,label=\"NeatMS\")\n",
    "makeROCPlot(y_test_scores_neat_ms_TL,y_test[:,1],noSkill=False,label=\"NeatMS_TL\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(datadir+\"ROC_TL.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>active PD</th>\n",
       "      <td>0.741497</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.793103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeatMS</th>\n",
       "      <td>0.421769</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeatMS TL</th>\n",
       "      <td>0.687075</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.574713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy  precision    recall\n",
       "active PD  0.741497   0.775281  0.793103\n",
       "NeatMS     0.421769   0.519231  0.310345\n",
       "NeatMS TL  0.687075   0.847458  0.574713"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results = {\"active PD\":{},\"NeatMS\":{},\"NeatMS TL\":{}}\n",
    "for metricFunc,name in zip([met.accuracy_score,met.precision_score,met.recall_score],[\"accuracy\",\"precision\",\"recall\"]):\n",
    "    acc_results[\"active PD\"][name] = metricFunc(y_test[:,1],y_test_scores_active_syn[:,1] > cutoff)\n",
    "    acc_results[\"NeatMS\"][name] = metricFunc(y_test[:,1],y_test_scores_neat_ms > 0.25)\n",
    "    acc_results[\"NeatMS TL\"][name] = metricFunc(y_test[:,1],y_test_scores_neat_ms_TL > 0.25)\n",
    "\n",
    "acc_results = pd.DataFrame.from_dict(acc_results,orient=\"index\")\n",
    "acc_results.to_csv(datadir + \"accuracy_results_TL.csv\")\n",
    "acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
